{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libreries \n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import selenium\n",
    "#let's first connect web drivers\n",
    "\n",
    "#driver = webdriver.Chrome(r\"D:\\chromedriver_win32\\chromedriver.exe\")  #optional\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")                         #uploded with local project file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.naukri.com/'  #set url here\n",
    "driver.get(url)                  \n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')     #we can find it by id even we can find it with xpath\n",
    "search_job\n",
    "search_job.send_keys(\"Data Analyst\")                         #send on web browser we have to write Data Analyst\n",
    "search_loc =driver.find_element_by_id(\"qsb-location-sugg\")   #we can find it by id even we can find it with xpath\n",
    "search_loc.send_keys(\"Bangalore\")                            #send on web browser we have to write Banglore\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")      #we can find it by id even we can find it with xpath\n",
    "search_btn.click()                                             #btn click\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Zilingo.com</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst (Data Stewards)//Immediate Joiner...</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst with Replicon Software</td>\n",
       "      <td>Replicon Software (India) Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst / Sr. Data Analyst - SQL</td>\n",
       "      <td>Naukri Premium - Employer Services</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>1-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                      Data analysts   \n",
       "2                                      Data analysts   \n",
       "3                                       Data Analyst   \n",
       "4  Data Analyst (Data Stewards)//Immediate Joiner...   \n",
       "5                Data Analyst with Replicon Software   \n",
       "6              Data Analyst / Sr. Data Analyst - SQL   \n",
       "7                                Senior Data Analyst   \n",
       "8                                Senior Data Analyst   \n",
       "9                                Senior Data Analyst   \n",
       "\n",
       "                              Company Experience             Location  \n",
       "0   Flipkart Internet Private Limited    4-5 Yrs  Bangalore/Bengaluru  \n",
       "1              IBM India Pvt. Limited    3-5 Yrs  Bangalore/Bengaluru  \n",
       "2              IBM India Pvt. Limited    5-6 Yrs  Bengaluru/Bangalore  \n",
       "3                         Zilingo.com    0-4 Yrs  Bangalore/Bengaluru  \n",
       "4                  Tech Mahindra Ltd.   5-10 Yrs  Bangalore/Bengaluru  \n",
       "5   Replicon Software (India) Pvt Ltd    2-4 Yrs  Bangalore/Bengaluru  \n",
       "6  Naukri Premium - Employer Services    2-5 Yrs  Bangalore/Bengaluru  \n",
       "7                     Publicis Groupe    5-9 Yrs  Bangalore/Bengaluru  \n",
       "8                     Publicis Groupe    6-8 Yrs  Bangalore/Bengaluru  \n",
       "9                     Publicis Groupe    1-7 Yrs  Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Titile\n",
    "Titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "job_titles=[]              #empty tag \n",
    "for i in Titles_tags:      \n",
    "    job_titles.append(i.text)\n",
    "\n",
    "job_titles \n",
    "#Experience_tags\n",
    "Experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "Experience_tags\n",
    "job_exp=[]\n",
    "for i in Experience_tags:\n",
    "    job_exp.append(i.text)\n",
    "job_exp \n",
    "\n",
    "#salary_tags\n",
    "salary_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']//span\")\n",
    "salary_tags\n",
    "#Now we will run for loop to find all data\n",
    "salary_exp=[]\n",
    "for i in salary_tags:\n",
    "    salary_exp.append(i.text)\n",
    "salary_exp \n",
    "\n",
    "#desrcriptionTag\n",
    "desrcriptionTag=driver.find_elements_by_xpath(\"//div[@class='job-description fs12 grey-text']\")\n",
    "desrcriptionTag\n",
    "descriptionJob=[]\n",
    "for i in desrcriptionTag:\n",
    "    descriptionJob.append(i.text)\n",
    "descriptionJob\n",
    "\n",
    "#locationJob\n",
    "locationJob=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "locationJob\n",
    "locationForJob=[]\n",
    "for i in locationJob:\n",
    "    locationForJob.append(i.text)\n",
    "locationForJob\n",
    "\n",
    "#Company\n",
    "Companytags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "Companytags\n",
    "#Now we will run for loop to find all data\n",
    "job_Company=[]              #empty tag \n",
    "for i in Companytags:      \n",
    "    job_Company.append(i.text)\n",
    "\n",
    "job_Company \n",
    "print(len(job_titles),len(job_exp),len(salary_exp),len(job_Company),len(locationForJob))\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Company']=job_Company\n",
    "jobs['Experience']=job_exp\n",
    "jobs['Location']=locationForJob\n",
    "jobs[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 ='https://www.naukri.com/'  #set url here\n",
    "driver.get(url2)                  \n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')     #we can find it by id even we can find it with xpath\n",
    "search_job\n",
    "search_job.send_keys(\"Data Scientist\")                         #send on web browser we have to write Data Analyst\n",
    "search_loc =driver.find_element_by_id(\"qsb-location-sugg\")   #we can find it by id even we can find it with xpath\n",
    "search_loc.send_keys(\"Bangalore\")                            #send on web browser we have to write Banglore\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")      #we can find it by id even we can find it with xpath\n",
    "search_btn.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-senior-data-scientist-fractal-analytics-ltd-mumbai-gurgaon-gurugram-bangalore-bengaluru-4-to-8-years-290621500776?src=jobsearchDesk&sid=16251632532458385&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-nielsen-india-private-limited-chennai-bangalore-bengaluru-vadodara-baroda-3-to-5-years-290621001647?src=jobsearchDesk&sid=16251632532458385&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bangalore-bengaluru-6-to-11-years-080221900886?src=jobsearchDesk&sid=16251632532458385&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-roppen-transportation-services-private-limited-bangalore-bengaluru-5-to-8-years-010721000825?src=jobsearchDesk&sid=16251632532458385&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-nielseniq-bangalore-bengaluru-3-to-5-years-300621501250?src=jobsearchDesk&sid=16251632532458385&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-gojek-tech-bangalore-bengaluru-3-to-6-years-300621500215?src=jobsearchDesk&sid=16251632532458385&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-go-jek-india-bangalore-bengaluru-5-to-10-years-300621500214?src=jobsearchDesk&sid=16251632532458385&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-publicis-groupe-bangalore-bengaluru-2-to-5-years-290621500896?src=jobsearchDesk&sid=16251632532458385&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-baker-hughes-incorporated-bangalore-bengaluru-3-to-7-years-010721501049?src=jobsearchDesk&sid=16251632532458385&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-payments-airbnb-global-capability-center-private-limited-bangalore-bengaluru-4-to-6-years-300621903935?src=jobsearchDesk&sid=16251632532458385&xp=10&px=1']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_Opening_urls=[]\n",
    "\n",
    "url= driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in url[:10]:\n",
    "    job_Opening_urls.append(i.get_attribute('href'))\n",
    "job_Opening_urls    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Artificial Intelligence and Machine Learning (AIML) group at Fractal Analytics is actively involved in helping Fortune 500 companies by enabling them to discover how they can leverage their data using advanced and sophisticated AI/ML algorithms for which we are looking for Data Scientists with the capability to work on independent statistical and machine learning research/ projects. If you are a problem solver with a curiosity for exploring new techniques and technologies in AIML space, then we would like to talk with you.\\nJob Responsibilities\\nAbility to understand a problem statement and implement analytical solutions techniques independently with independently / proactively / thought-leadership.\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company/client data to drive business solutions.\\nFast learner: ability to learn and pick up a new language/tool/ platform quickly.\\nConceptualize, design, and deliver high-quality solutions and insightful analysis.\\nConduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problems.\\nCollaborate and Coordinate with different functional teams(engineering and product development) to implement models and monitor outcomes.\\nAbility to deliver AIML based solutions around a host of domains and problems, with some of them being: Customer Segmentation Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Price Optimization\\nExperience Required:\\nExpert level proficiency in at least one of R and Python.\\nAbility to create efficient solutions to complex problems. Strong skills in data-structures and ML algorithms.\\nExperience of working on end-to-end data science pipeline: problem scoping, data gathering, EDA, modelling, insights, visualizations, monitoring and maintenance.\\nProblem-solving: Ability to break the problem into small parts and applying relevant techniques to drive required outcomes.\\nIntermediate to advanced knowledge of machine learning, probability theory, statistics, and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.\\nWe use regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modeling, dimensionality reduction, SEM, GLM, GLMM, clustering, Deep learning etc. on a regular basis. If you know few of them you are good to go.\\nGood to Have:\\nExperience in one of the upcoming technologies like deep learning, NLP, image processing, recommender systems\\nExperience of working in on one or more domains:\\nCPG: pricing and promotion analytics, marketing analytics, trade promotions, supply chain management\\nBFSI: cross-sell, up-sell, campaign analytics, treasury analytics, fraud detection\\nHealthcare: medical adherence, medical risk profiling, EHR data, fraud-waste-abuse\\nExperience in working with Linux computing environment and use of command line tools like sed/awk\\nGood grasp on databases including RDBMS, NoSQL, MongoDB etc.\\nEducation Qualification\\nB.Tech / M.Tech in Computer Science / Mathematics / Signal Processing or related fields.',\n",
       " 'ABOUT THIS JOB\\nNielsenIQ Advanced Analytics team develops and promotes a portfolio of global products. Leveraging NielsenIQs unparalleled data and global platforms, the Advanced Analytics team creates solutions to enable our clients to make better business decisions every day.  We partner with Product Owners and Core Technology Teams to build scalable, always on,  analytic products using relevant modeling/ML techniques.\\nWe’re looking for a passionate and talented Senior Data Scientist to join our growing team. In this role, you’ll have the chance to roll up your sleeves and apply data science methods and analytics to sustain NielsenIQ Analytics growth. Successful candidates are intellectually curious builders and active learners who are biased toward action, new problem solving.\\nRoles & Responsibilities :\\nUnderstand business issues, stakeholder requirement and expectations\\nPerform relevant modeling analysis and POC exploring multiple techniques\\nEnsure Analytics model quality\\nDocument and present findings and recommendations on methodology in a structured way to various stakeholder or partnering teams (Engineering, Tech, Product leader).\\nWork closely with the Engineering and Tech team to convert those POC into fully scalable products.\\nActive and effective collaboration with other project team members (other Data Scientist, Data Steward, Technology Engineer)\\nCollaboratively manage projects from timeline creation to project completion, managing expectations with leaders and colleagues\\nEncourage team building, best practices sharing especially with more junior team members.\\nStay abreast of developments in the area to ensure bringing the most appropriate solutions to our business\\nAbout You\\nYou’ve built a decent track record in research and data analytics. And you have the communication chops to translate it all into conversations. While you’ve worked with global cross-functional teams, you can also put your head down and focus on independent projects. Seeing the big picture takes attention to detail. Keeping up with the fast-changing world of technology takes someone who recognizes that. You know what’s happening in big data and you’re ready to influence what’s next.\\nQualifications\\nMasters degree in Data Sciences, mathematics or a closely related field\\n3 to 5 years of experience as a Data Scientist in the business\\nStrong knowledge of statistical modelling, machine learning.\\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms\\nExperience with Optimisation techniques: linear programming, integer programming, genetic algorithm, constrained optimisation\\nExperience in working on distributed or cloud computing platforms such as Google Cloud or Microsoft Azure\\nProficiency in Data Science coding languages like Python, PySpark, SQL, R in a cloud environment like DataBricks\\nExperience using collaborative development tools (git).\\nExperience working with Agile methodologies (SCRUM)\\nStrong problem solving and excellent communication skills, independent working style\\nExperience in an FMCG company is a strong plus',\n",
       " 'Roles and Responsibilities\\nRequirements :\\n\\n- 6-9 years of strong experience in data mining, machine learning and statistical analysis.\\n\\n- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Python/ R/ Matlab etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.',\n",
       " 'Our Cause:\\nRapido is Indias largest bike taxi player focused on solving the first and last mile connectivity problem for India. The primary focus is mobility and changing all facets of mobility across India.We believe that 2 Wheeler are the right mode of transport for developing countries like India and have much more scope than 4 wheelers, which is also reflected in the fact that the number of 2 wheelers is significantly more than the number of 4-wheelers.We have operations in close to 100 cities and are the undisputed market leader in this space. Growing close to 500% year-on-year, we have ambitious targets set for ourselves in the future as well.\\n\\nRole and Responsibilities:\\n\\nTranslating business requirements into analytical solutions\\nPerform data analysis (with a representative sample data slice) and build/prototype the model(s)\\nWork with business users and/or other data scientists to define and close on the model design\\nProvide inputs to the data ingestion/engineering team on input data required by the model, size, format, associations, cleansing required\\nIdentify/Provide approach and data to validate the model(s)\\nCollaborate with a technology/data engineering team to transfer the business understanding, get the model productionized and validate the output along with business users\\nTune the model(s) to improve results provided over time\\nUnderstand business challenges and goals to formulate the approach for data analysis and model creation that will support business decision making\\nDo hands-on data analysis and model creation\\nWork closely with data analysts in the team to define and execute on EDA and experiment roadmap\\nWork in highly collaborative teams that strive to build quality systems and provide business value\\nContinually learn and develop your career\\nMust have:\\n\\nPassion for understanding business problems and trying to address them by leveraging data - characterized by high-volume, high dimensionality from multiple sources\\nAbility to communicate complex models and analysis in a clear and precise manner\\nExperience with building predictive statistical, behavioral or other models via supervised and unsupervised machine learning, statistical analysis, and other predictive modeling techniques.\\nExperience using R, Python or equivalent statistical/data analysis tools. Ability to transfer that knowledge to different tools\\nExperience with matrices, distributions and probability\\nProficiency with relational databases and NoSQL\\nExperience in Machine Learning, Deep Learning solution, Neural Networks is preferred.\\nWorked in a big data environment before alongside a data engineering team (and data visualization team, data and business analysts)\\nEducation and Experience:\\nBE/BS/MS or equivalent in Applied mathematics, statistics, physics, computer science or operations research background is a MUST. Minimum 5-8 years as Data Scientist in real business impact projects',\n",
       " 'Roles Responsibilities :\\nUnderstand business issues, stakeholder requirement and expectations\\nPerform relevant modeling analysis and POC exploring multiple techniques\\nEnsure Analytics model quality\\nDocument and present findings and recommendations on methodology in a structured way to various stakeholder or partnering teams (Engineering, Tech, Product leader ).\\nWork closely with the Engineering and Tech team to convert those POC into fully scalable products.\\nActive and effective collaboration with other project team members (other Data Scientist, Data Steward, Technology Engineer )\\nCollaboratively manage projects from timeline creation to project completion, managing expectations with leaders and colleagues\\nEncourage team building, best practices sharing especially with more junior team members.\\nStay abreast of developments in the area to ensure bringing the most appropriate solutions to our business\\nAbout You\\nYou ve built a decent track record in research and data analytics. And you have the communication chops to translate it all into conversations. While you ve worked with global cross-functional teams, you can also put your head down and focus on independent projects. Seeing the big picture takes attention to detail. Keeping up with the fast-changing world of technology takes someone who recognizes that. You know what s happening in big data and you re ready to influence what s next.\\nQualifications\\nMasters degree in Data Sciences, mathematics or a closely related field\\n3 to 5 years of experience as a Data Scientist in the business\\nStrong knowledge of statistical modelling, machine learning.\\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms\\nExperience with Optimisation techniques: linear programming, integer programming, genetic algorithm, constrained optimisation\\nExperience in working on distributed or cloud computing platforms such as Google Cloud or Microsoft Azure\\nProficiency in Data Science coding languages like Python, PySpark, SQL, R in a cloud environment like DataBricks\\nExperience using collaborative development tools (git ).\\nExperience working with Agile methodologies (SCRUM)\\nStrong problem solving and excellent communication skills, independent working style\\nExperience in an FMCG company is a strong plus',\n",
       " 'As our Senior Data Scientist, youll be an integral player in the Marketplace Data Science team based in Bengaluru. With the latest cutting-edge data science tech at your disposal, youll focus your efforts on bringing our Marketplace systems (i.e. supply, demand, and pricing) to the next level, employing various quantitative techniques such as Machine Learning, Optimization, Simulation, Bayesian Techniques to drive asymmetric values for our businesses at Gojek. Youll be heavily involved in ideation, research, and building prototypes, and the folks in the Data Science Platform will bring your models to production. Your efforts will directly influence the stability and scalability of Gojeks Marketplace stream, and thus to companys top and bottom line as a whole.\\n  What You Will Do\\nWork with Data Scientists, Machine Learning Engineers, and Business Users to build, deploy, and scale Data Science solutions on match-making, supply, pricing problems in Gojek that touch the company s baseline\\nUse your experience in Data Science, Machine Learning, Software Engineering, distributed systems to develop these systems, and work with the platform team to take the systems to production\\nWork with Business teams to continuously refine and improve the systems to cater to ever-changing Gojek needs\\nDesign and develop world class Data Science solutions to enhance the current stack of Marketplace algorithms for supply, demand, pricing\\nWhat You Will Need\\nAt least 6 years of experience as a Data Scientist or Machine Learning Engineer, with experience in Python, Golang/Java, and Unix\\nA Bachelors Degree in Computer Science, Statistics, Operations Research, or a relevant quantitative field\\nSolid knowledge of Data Science and Machine Learning fundamentals, with proven experience formulating Data Science solutions to business problems\\nProven ability to recognize business needs and to communicate with multiple stakeholders within the Product Management, Business and Operations teams\\nExperience in taking Data Science models to production\\nPrior academic or industry work experience with forecasting methods like auto-regressive models, Markov models, and Kernel-based methods\\nPrior experience with simulations for modeling the stochastic nature of marketplace supply and demand, and knowledge of the transportation and mobility space',\n",
       " 'As our Senior Data Scientist, youll be an integral player in the Marketplace Data Science team based in Bengaluru. With the latest cutting-edge data science tech at your disposal, youll focus your efforts on bringing our Marketplace systems (i.e. supply, demand, and pricing) to the next level, employing various quantitative techniques such as Machine Learning, Optimization, Simulation, Bayesian Techniques to drive asymmetric values for our businesses at Gojek. Youll be heavily involved in ideation, research, and building prototypes, and the folks in the Data Science Platform will bring your models to production. Your efforts will directly influence the stability and scalability of Gojeks Marketplace stream, and thus to companys top and bottom line as a whole.\\n  What You Will Do\\nWork with Data Scientists, Machine Learning Engineers, and Business Users to build, deploy, and scale Data Science solutions on match-making, supply, pricing problems in Gojek that touch the company s baseline\\nUse your experience in Data Science, Machine Learning, Software Engineering, distributed systems to develop these systems, and work with the platform team to take the systems to production\\nWork with Business teams to continuously refine and improve the systems to cater to ever-changing Gojek needs\\nDesign and develop world class Data Science solutions to enhance the current stack of Marketplace algorithms for supply, demand, pricing\\nWhat You Will Need\\nAt least 6 years of experience as a Data Scientist or Machine Learning Engineer, with experience in Python, Golang/Java, and Unix\\nA Bachelors Degree in Computer Science, Statistics, Operations Research, or a relevant quantitative field\\nSolid knowledge of Data Science and Machine Learning fundamentals, with proven experience formulating Data Science solutions to business problems\\nProven ability to recognize business needs and to communicate with multiple stakeholders within the Product Management, Business and Operations teams\\nExperience in taking Data Science models to production\\nPrior academic or industry work experience with forecasting methods like auto-regressive models, Markov models, and Kernel-based methods\\nPrior experience with simulations for modeling the stochastic nature of marketplace supply and demand, and knowledge of the transportation and mobility space',\n",
       " 'Epsilon India team is looking for a talented team player in a Senior Data Scientist. You are an expert, mentor and advocate. You have strong machine learning and deep learning background and are passionate about transforming data into ml models. You welcome the challenge of data science and are proficient in Python, Spark MLLib, Tensorflow, Keras, ML algortihms and Deep Neural Networks, Big Data. You must be self-driven, take initiative and want to work in a dynamic, busy and innovative group.\\nYou will work with a distributed team (onshore and offshore) and work closely with a broadly talented team of delivery management, business analysts, visual designers, analytics, developers, and QA. You will work directly with clients to own data science solutions as a member of the Data Sciences MML Cloud Services team, and will operate as part of the product team to extend the Platform functionality when not supporting client projects\\nPerform hands-on analysis of large volumes of web analytics, transaction, customer data, second and third-party data. Work with complex data structure, manipulate, cleanse data and perform statistical analysis\\nDesign and Implement Machine learning models using Spark ML, Python, Map-Reduce, Hive, HDFS, Spring, Hibernate and Java\\nDesign and implement Deep neural network models using Tensorflow, Pytorch, Keras and Python\\nCreate engaging and meaningful data visualizations of findings linked to clear client business impact.\\nDevelop machine learning pipelines with big data design principles in MS Azure cloud using Azure Data Factory\\nOwn end to end implementations of Marketing machine learning models such as Churn, CLV, Propensity, Affinity models.\\n\\n\\nQualifications\\nExperience with large scale distributed databases and computing systems like Hadoop, HDInsight or DataBricks\\nStrong passion for understanding key business problems, bringing together a team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences\\nProven capability to deliver end-to-end analyses by asking the right questions, extracting data, and building predictive models to ensure actionable results.\\nExcellent communication interpersonal skills with an ability to communicate ideas.\\nMS or Ph.D. in Computer Science, Math, Physics, or equivalent education/professional experience is required.\\n6+ years of overall IT experience with 2+ years in a data science role with demonstrable experience\\nDeep experience in machine learning with Spark and Azure Machine Learning and Cognitive Services.\\nAzure Cloud experience required. Azure Data Factory experience preferred.\\nStrong experience in DNN models using Tensorflow v1.8 above, Keras, Pytorch\\nExperience with sequence modeling using RNNs/LSTMs is good to have\\nStrong experience in at least one database technology (i.e. Hive, PrestoDb etc.)\\nStrong experience in at least one programming language (i.e. Python, R, C, C++ is plus)\\nExperience working with different query languages (i.e. PL-SQL, T-SQL)\\nUnderstanding and experience working with cloud infrastructure services like Azure and Amazon Web Services. Azure preferred.\\nExperience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.)\\nStrong passion for understanding key business problems, bringing together the team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences',\n",
       " 'As a Sr Data Scientist, you will be responsible for:\\nWorking with business stakeholders to understand the business problem/requirements and helping define analytic objectives\\nBuilding the state of art machine learning or computer vision models according to the industry use case. Develop re-usable components that can be applied to similar problem across industry\\nBeing responsible for development of advanced computer vision solutions for detection of defects in the industrial inspection images (Visual or CT/Xray images).\\nImplementing computer vision technique in image classification, object detection, segmentation, etc. using frameworks like TensorFlow & PyTorch\\nIterating and improve the model performances using appropriate transfer learning techniques\\nBuilding end to end Machine learning or Deep learning pipelines and follow the deployment best practices (Flask, FastAPI, Streamlit, Docker ,etc.)\\nHaving Ability to deploy machine or deep learning solutions in to production (Edge or cloud environment)\\nFuel your passion\\nTo be successful in this role you will:\\nHave a Bachelors / Phd in Computer Science or STEM Majors (Science, Technology, Engineering and Math) with 2+ yrs experience in building computer vision solutions for the industrial use case.\\nHave Minimum 6 yrs of experience with machine learning, computer vision algorithms, and framework to solve object detection, recognition, tracking, segmentation, etc.\\nHave experience on deep learning & machine learning libraries Tensorflow, Pytorch, Keras, sklearn, OpenCV, etc.\\nHave Knowledge of Convolutional Networks and Deep Learning algorithms\\nHave Solid programming skills with Python and/or non-scripting languages\\nExperience working with NDT inspection (CT/Xray image) data is a plus\\nExperience with Docker containers & cloud deployment is plus',\n",
       " 'The Challenge\\nBe a thought leader, partner with your cross-functional partners to foster a data driven payments organization.\\nWith a focus on Payments compliance and keeping our platform safe, anticipate and detect new fraud trends and regulatory requirements.\\nDefine and evaluate key metrics. Build the data foundation you need, in partnership with the data engineering team.\\nDeliver actionable user-insights to build the best products and models\\nDesign experiments to measure the impact of new payments features\\nEmpower the product and engineering teams to make data-driven decisions\\nWhat you need to succeed\\n4+ years industry experience in a quantitative analysis role. Experience in Payments a strong plus\\nFluent in SQL and proficiency in analytical tools such as Python, R, etc.\\nBackground in statistics and experience with experimentation\\nSolid understanding of product analytics\\nExperience or willingness to learn tools to create data pipelines using Airflow/Minerva\\nAbility to communicate clearly and effectively to cross functional partners of\\nvarying technical levels']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_Description=[]\n",
    "\n",
    "\n",
    "for i in job_Opening_urls:   \n",
    "    driver.get(i)\n",
    "    try:\n",
    "     \n",
    "        job_title=driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\") \n",
    "        job_Description.append(job_title.text).replace('\\n','') \n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "job_Description   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Artificial Intelligence and Machine Learning (AIML) group at Fractal Analytics is actively involved in helping Fortune 500 companies by enabling them to discover how they can leverage their data using advanced and sophisticated AI/ML algorithms for which we are looking for Data Scientists with the capability to work on independent statistical and machine learning research/ projects. If you are a problem solver with a curiosity for exploring new techniques and technologies in AIML space, then we would like to talk with you.\\nJob Responsibilities\\nAbility to understand a problem statement and implement analytical solutions techniques independently with independently / proactively / thought-leadership.\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company/client data to drive business solutions.\\nFast learner: ability to learn and pick up a new language/tool/ platform quickly.\\nConceptualize, design, and deliver high-quality solutions and insightful analysis.\\nConduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problems.\\nCollaborate and Coordinate with different functional teams(engineering and product development) to implement models and monitor outcomes.\\nAbility to deliver AIML based solutions around a host of domains and problems, with some of them being: Customer Segmentation Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Price Optimization\\nExperience Required:\\nExpert level proficiency in at least one of R and Python.\\nAbility to create efficient solutions to complex problems. Strong skills in data-structures and ML algorithms.\\nExperience of working on end-to-end data science pipeline: problem scoping, data gathering, EDA, modelling, insights, visualizations, monitoring and maintenance.\\nProblem-solving: Ability to break the problem into small parts and applying relevant techniques to drive required outcomes.\\nIntermediate to advanced knowledge of machine learning, probability theory, statistics, and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.\\nWe use regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modeling, dimensionality reduction, SEM, GLM, GLMM, clustering, Deep learning etc. on a regular basis. If you know few of them you are good to go.\\nGood to Have:\\nExperience in one of the upcoming technologies like deep learning, NLP, image processing, recommender systems\\nExperience of working in on one or more domains:\\nCPG: pricing and promotion analytics, marketing analytics, trade promotions, supply chain management\\nBFSI: cross-sell, up-sell, campaign analytics, treasury analytics, fraud detection\\nHealthcare: medical adherence, medical risk profiling, EHR data, fraud-waste-abuse\\nExperience in working with Linux computing environment and use of command line tools like sed/awk\\nGood grasp on databases including RDBMS, NoSQL, MongoDB etc.\\nEducation Qualification\\nB.Tech / M.Tech in Computer Science / Mathematics / Signal Processing or related fields.',\n",
       " 'ABOUT THIS JOB\\nNielsenIQ Advanced Analytics team develops and promotes a portfolio of global products. Leveraging NielsenIQs unparalleled data and global platforms, the Advanced Analytics team creates solutions to enable our clients to make better business decisions every day.  We partner with Product Owners and Core Technology Teams to build scalable, always on,  analytic products using relevant modeling/ML techniques.\\nWe’re looking for a passionate and talented Senior Data Scientist to join our growing team. In this role, you’ll have the chance to roll up your sleeves and apply data science methods and analytics to sustain NielsenIQ Analytics growth. Successful candidates are intellectually curious builders and active learners who are biased toward action, new problem solving.\\nRoles & Responsibilities :\\nUnderstand business issues, stakeholder requirement and expectations\\nPerform relevant modeling analysis and POC exploring multiple techniques\\nEnsure Analytics model quality\\nDocument and present findings and recommendations on methodology in a structured way to various stakeholder or partnering teams (Engineering, Tech, Product leader).\\nWork closely with the Engineering and Tech team to convert those POC into fully scalable products.\\nActive and effective collaboration with other project team members (other Data Scientist, Data Steward, Technology Engineer)\\nCollaboratively manage projects from timeline creation to project completion, managing expectations with leaders and colleagues\\nEncourage team building, best practices sharing especially with more junior team members.\\nStay abreast of developments in the area to ensure bringing the most appropriate solutions to our business\\nAbout You\\nYou’ve built a decent track record in research and data analytics. And you have the communication chops to translate it all into conversations. While you’ve worked with global cross-functional teams, you can also put your head down and focus on independent projects. Seeing the big picture takes attention to detail. Keeping up with the fast-changing world of technology takes someone who recognizes that. You know what’s happening in big data and you’re ready to influence what’s next.\\nQualifications\\nMasters degree in Data Sciences, mathematics or a closely related field\\n3 to 5 years of experience as a Data Scientist in the business\\nStrong knowledge of statistical modelling, machine learning.\\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms\\nExperience with Optimisation techniques: linear programming, integer programming, genetic algorithm, constrained optimisation\\nExperience in working on distributed or cloud computing platforms such as Google Cloud or Microsoft Azure\\nProficiency in Data Science coding languages like Python, PySpark, SQL, R in a cloud environment like DataBricks\\nExperience using collaborative development tools (git).\\nExperience working with Agile methodologies (SCRUM)\\nStrong problem solving and excellent communication skills, independent working style\\nExperience in an FMCG company is a strong plus',\n",
       " 'Roles and Responsibilities\\nRequirements :\\n\\n- 6-9 years of strong experience in data mining, machine learning and statistical analysis.\\n\\n- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Python/ R/ Matlab etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.',\n",
       " 'Our Cause:\\nRapido is Indias largest bike taxi player focused on solving the first and last mile connectivity problem for India. The primary focus is mobility and changing all facets of mobility across India.We believe that 2 Wheeler are the right mode of transport for developing countries like India and have much more scope than 4 wheelers, which is also reflected in the fact that the number of 2 wheelers is significantly more than the number of 4-wheelers.We have operations in close to 100 cities and are the undisputed market leader in this space. Growing close to 500% year-on-year, we have ambitious targets set for ourselves in the future as well.\\n\\nRole and Responsibilities:\\n\\nTranslating business requirements into analytical solutions\\nPerform data analysis (with a representative sample data slice) and build/prototype the model(s)\\nWork with business users and/or other data scientists to define and close on the model design\\nProvide inputs to the data ingestion/engineering team on input data required by the model, size, format, associations, cleansing required\\nIdentify/Provide approach and data to validate the model(s)\\nCollaborate with a technology/data engineering team to transfer the business understanding, get the model productionized and validate the output along with business users\\nTune the model(s) to improve results provided over time\\nUnderstand business challenges and goals to formulate the approach for data analysis and model creation that will support business decision making\\nDo hands-on data analysis and model creation\\nWork closely with data analysts in the team to define and execute on EDA and experiment roadmap\\nWork in highly collaborative teams that strive to build quality systems and provide business value\\nContinually learn and develop your career\\nMust have:\\n\\nPassion for understanding business problems and trying to address them by leveraging data - characterized by high-volume, high dimensionality from multiple sources\\nAbility to communicate complex models and analysis in a clear and precise manner\\nExperience with building predictive statistical, behavioral or other models via supervised and unsupervised machine learning, statistical analysis, and other predictive modeling techniques.\\nExperience using R, Python or equivalent statistical/data analysis tools. Ability to transfer that knowledge to different tools\\nExperience with matrices, distributions and probability\\nProficiency with relational databases and NoSQL\\nExperience in Machine Learning, Deep Learning solution, Neural Networks is preferred.\\nWorked in a big data environment before alongside a data engineering team (and data visualization team, data and business analysts)\\nEducation and Experience:\\nBE/BS/MS or equivalent in Applied mathematics, statistics, physics, computer science or operations research background is a MUST. Minimum 5-8 years as Data Scientist in real business impact projects',\n",
       " 'Roles Responsibilities :\\nUnderstand business issues, stakeholder requirement and expectations\\nPerform relevant modeling analysis and POC exploring multiple techniques\\nEnsure Analytics model quality\\nDocument and present findings and recommendations on methodology in a structured way to various stakeholder or partnering teams (Engineering, Tech, Product leader ).\\nWork closely with the Engineering and Tech team to convert those POC into fully scalable products.\\nActive and effective collaboration with other project team members (other Data Scientist, Data Steward, Technology Engineer )\\nCollaboratively manage projects from timeline creation to project completion, managing expectations with leaders and colleagues\\nEncourage team building, best practices sharing especially with more junior team members.\\nStay abreast of developments in the area to ensure bringing the most appropriate solutions to our business\\nAbout You\\nYou ve built a decent track record in research and data analytics. And you have the communication chops to translate it all into conversations. While you ve worked with global cross-functional teams, you can also put your head down and focus on independent projects. Seeing the big picture takes attention to detail. Keeping up with the fast-changing world of technology takes someone who recognizes that. You know what s happening in big data and you re ready to influence what s next.\\nQualifications\\nMasters degree in Data Sciences, mathematics or a closely related field\\n3 to 5 years of experience as a Data Scientist in the business\\nStrong knowledge of statistical modelling, machine learning.\\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms\\nExperience with Optimisation techniques: linear programming, integer programming, genetic algorithm, constrained optimisation\\nExperience in working on distributed or cloud computing platforms such as Google Cloud or Microsoft Azure\\nProficiency in Data Science coding languages like Python, PySpark, SQL, R in a cloud environment like DataBricks\\nExperience using collaborative development tools (git ).\\nExperience working with Agile methodologies (SCRUM)\\nStrong problem solving and excellent communication skills, independent working style\\nExperience in an FMCG company is a strong plus',\n",
       " 'As our Senior Data Scientist, youll be an integral player in the Marketplace Data Science team based in Bengaluru. With the latest cutting-edge data science tech at your disposal, youll focus your efforts on bringing our Marketplace systems (i.e. supply, demand, and pricing) to the next level, employing various quantitative techniques such as Machine Learning, Optimization, Simulation, Bayesian Techniques to drive asymmetric values for our businesses at Gojek. Youll be heavily involved in ideation, research, and building prototypes, and the folks in the Data Science Platform will bring your models to production. Your efforts will directly influence the stability and scalability of Gojeks Marketplace stream, and thus to companys top and bottom line as a whole.\\n  What You Will Do\\nWork with Data Scientists, Machine Learning Engineers, and Business Users to build, deploy, and scale Data Science solutions on match-making, supply, pricing problems in Gojek that touch the company s baseline\\nUse your experience in Data Science, Machine Learning, Software Engineering, distributed systems to develop these systems, and work with the platform team to take the systems to production\\nWork with Business teams to continuously refine and improve the systems to cater to ever-changing Gojek needs\\nDesign and develop world class Data Science solutions to enhance the current stack of Marketplace algorithms for supply, demand, pricing\\nWhat You Will Need\\nAt least 6 years of experience as a Data Scientist or Machine Learning Engineer, with experience in Python, Golang/Java, and Unix\\nA Bachelors Degree in Computer Science, Statistics, Operations Research, or a relevant quantitative field\\nSolid knowledge of Data Science and Machine Learning fundamentals, with proven experience formulating Data Science solutions to business problems\\nProven ability to recognize business needs and to communicate with multiple stakeholders within the Product Management, Business and Operations teams\\nExperience in taking Data Science models to production\\nPrior academic or industry work experience with forecasting methods like auto-regressive models, Markov models, and Kernel-based methods\\nPrior experience with simulations for modeling the stochastic nature of marketplace supply and demand, and knowledge of the transportation and mobility space',\n",
       " 'As our Senior Data Scientist, youll be an integral player in the Marketplace Data Science team based in Bengaluru. With the latest cutting-edge data science tech at your disposal, youll focus your efforts on bringing our Marketplace systems (i.e. supply, demand, and pricing) to the next level, employing various quantitative techniques such as Machine Learning, Optimization, Simulation, Bayesian Techniques to drive asymmetric values for our businesses at Gojek. Youll be heavily involved in ideation, research, and building prototypes, and the folks in the Data Science Platform will bring your models to production. Your efforts will directly influence the stability and scalability of Gojeks Marketplace stream, and thus to companys top and bottom line as a whole.\\n  What You Will Do\\nWork with Data Scientists, Machine Learning Engineers, and Business Users to build, deploy, and scale Data Science solutions on match-making, supply, pricing problems in Gojek that touch the company s baseline\\nUse your experience in Data Science, Machine Learning, Software Engineering, distributed systems to develop these systems, and work with the platform team to take the systems to production\\nWork with Business teams to continuously refine and improve the systems to cater to ever-changing Gojek needs\\nDesign and develop world class Data Science solutions to enhance the current stack of Marketplace algorithms for supply, demand, pricing\\nWhat You Will Need\\nAt least 6 years of experience as a Data Scientist or Machine Learning Engineer, with experience in Python, Golang/Java, and Unix\\nA Bachelors Degree in Computer Science, Statistics, Operations Research, or a relevant quantitative field\\nSolid knowledge of Data Science and Machine Learning fundamentals, with proven experience formulating Data Science solutions to business problems\\nProven ability to recognize business needs and to communicate with multiple stakeholders within the Product Management, Business and Operations teams\\nExperience in taking Data Science models to production\\nPrior academic or industry work experience with forecasting methods like auto-regressive models, Markov models, and Kernel-based methods\\nPrior experience with simulations for modeling the stochastic nature of marketplace supply and demand, and knowledge of the transportation and mobility space',\n",
       " 'Epsilon India team is looking for a talented team player in a Senior Data Scientist. You are an expert, mentor and advocate. You have strong machine learning and deep learning background and are passionate about transforming data into ml models. You welcome the challenge of data science and are proficient in Python, Spark MLLib, Tensorflow, Keras, ML algortihms and Deep Neural Networks, Big Data. You must be self-driven, take initiative and want to work in a dynamic, busy and innovative group.\\nYou will work with a distributed team (onshore and offshore) and work closely with a broadly talented team of delivery management, business analysts, visual designers, analytics, developers, and QA. You will work directly with clients to own data science solutions as a member of the Data Sciences MML Cloud Services team, and will operate as part of the product team to extend the Platform functionality when not supporting client projects\\nPerform hands-on analysis of large volumes of web analytics, transaction, customer data, second and third-party data. Work with complex data structure, manipulate, cleanse data and perform statistical analysis\\nDesign and Implement Machine learning models using Spark ML, Python, Map-Reduce, Hive, HDFS, Spring, Hibernate and Java\\nDesign and implement Deep neural network models using Tensorflow, Pytorch, Keras and Python\\nCreate engaging and meaningful data visualizations of findings linked to clear client business impact.\\nDevelop machine learning pipelines with big data design principles in MS Azure cloud using Azure Data Factory\\nOwn end to end implementations of Marketing machine learning models such as Churn, CLV, Propensity, Affinity models.\\n\\n\\nQualifications\\nExperience with large scale distributed databases and computing systems like Hadoop, HDInsight or DataBricks\\nStrong passion for understanding key business problems, bringing together a team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences\\nProven capability to deliver end-to-end analyses by asking the right questions, extracting data, and building predictive models to ensure actionable results.\\nExcellent communication interpersonal skills with an ability to communicate ideas.\\nMS or Ph.D. in Computer Science, Math, Physics, or equivalent education/professional experience is required.\\n6+ years of overall IT experience with 2+ years in a data science role with demonstrable experience\\nDeep experience in machine learning with Spark and Azure Machine Learning and Cognitive Services.\\nAzure Cloud experience required. Azure Data Factory experience preferred.\\nStrong experience in DNN models using Tensorflow v1.8 above, Keras, Pytorch\\nExperience with sequence modeling using RNNs/LSTMs is good to have\\nStrong experience in at least one database technology (i.e. Hive, PrestoDb etc.)\\nStrong experience in at least one programming language (i.e. Python, R, C, C++ is plus)\\nExperience working with different query languages (i.e. PL-SQL, T-SQL)\\nUnderstanding and experience working with cloud infrastructure services like Azure and Amazon Web Services. Azure preferred.\\nExperience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.)\\nStrong passion for understanding key business problems, bringing together the team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences',\n",
       " 'As a Sr Data Scientist, you will be responsible for:\\nWorking with business stakeholders to understand the business problem/requirements and helping define analytic objectives\\nBuilding the state of art machine learning or computer vision models according to the industry use case. Develop re-usable components that can be applied to similar problem across industry\\nBeing responsible for development of advanced computer vision solutions for detection of defects in the industrial inspection images (Visual or CT/Xray images).\\nImplementing computer vision technique in image classification, object detection, segmentation, etc. using frameworks like TensorFlow & PyTorch\\nIterating and improve the model performances using appropriate transfer learning techniques\\nBuilding end to end Machine learning or Deep learning pipelines and follow the deployment best practices (Flask, FastAPI, Streamlit, Docker ,etc.)\\nHaving Ability to deploy machine or deep learning solutions in to production (Edge or cloud environment)\\nFuel your passion\\nTo be successful in this role you will:\\nHave a Bachelors / Phd in Computer Science or STEM Majors (Science, Technology, Engineering and Math) with 2+ yrs experience in building computer vision solutions for the industrial use case.\\nHave Minimum 6 yrs of experience with machine learning, computer vision algorithms, and framework to solve object detection, recognition, tracking, segmentation, etc.\\nHave experience on deep learning & machine learning libraries Tensorflow, Pytorch, Keras, sklearn, OpenCV, etc.\\nHave Knowledge of Convolutional Networks and Deep Learning algorithms\\nHave Solid programming skills with Python and/or non-scripting languages\\nExperience working with NDT inspection (CT/Xray image) data is a plus\\nExperience with Docker containers & cloud deployment is plus',\n",
       " 'The Challenge\\nBe a thought leader, partner with your cross-functional partners to foster a data driven payments organization.\\nWith a focus on Payments compliance and keeping our platform safe, anticipate and detect new fraud trends and regulatory requirements.\\nDefine and evaluate key metrics. Build the data foundation you need, in partnership with the data engineering team.\\nDeliver actionable user-insights to build the best products and models\\nDesign experiments to measure the impact of new payments features\\nEmpower the product and engineering teams to make data-driven decisions\\nWhat you need to succeed\\n4+ years industry experience in a quantitative analysis role. Experience in Payments a strong plus\\nFluent in SQL and proficiency in analytical tools such as Python, R, etc.\\nBackground in statistics and experience with experimentation\\nSolid understanding of product analytics\\nExperience or willingness to learn tools to create data pipelines using Airflow/Minerva\\nAbility to communicate clearly and effectively to cross functional partners of\\nvarying technical levels']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_Description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist, Payments']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_Titile=[]\n",
    "\n",
    "\n",
    "for i in job_Opening_urls[0:10]:   \n",
    "    driver.get(i)\n",
    "    try:\n",
    "     \n",
    "        job_Name=driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\") \n",
    "        job_Titile.append(job_Name.text).replace('\\n','') \n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "job_Titile   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_Titile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fractal Analytics',\n",
       " 'Nielsen',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'Roppen Transportation Services Private Limited',\n",
       " 'NielsenIQ',\n",
       " 'Gojek Tech',\n",
       " 'GO-JEK India',\n",
       " 'Publicis Groupe',\n",
       " 'Baker Hughes Incorporated',\n",
       " 'AIRBNB GLOBAL CAPABILITY CENTER PRIVATE LIMITED']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_Company=[]\n",
    "\n",
    "\n",
    "for i in job_Opening_urls[:10]:   \n",
    "    driver.get(i)\n",
    "    try:\n",
    "     \n",
    "        job_Comp=driver.find_element_by_xpath(\"//div[@class='jd-header-comp-name']//a\") \n",
    "        job_Company.append(job_Comp.text).replace('\\n','') \n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "job_Company   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru, Vadodara',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_Location=[]\n",
    "\n",
    "\n",
    "for i in job_Opening_urls[:10]:   \n",
    "    driver.get(i)\n",
    "    try:\n",
    "     \n",
    "        job_Loc=driver.find_element_by_xpath(\"//div[@class='loc']//span\") \n",
    "        job_Location.append(job_Loc.text).replace('\\n','') \n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "job_Location   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>The Artificial Intelligence and Machine Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Vadodara</td>\n",
       "      <td>ABOUT THIS JOB\\nNielsenIQ Advanced Analytics t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nRequirements :\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Roppen Transportation Services Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Our Cause:\\nRapido is Indias largest bike taxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles Responsibilities :\\nUnderstand business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As our Senior Data Scientist, youll be an inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>GO-JEK India</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As our Senior Data Scientist, youll be an inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Epsilon India team is looking for a talented t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Baker Hughes Incorporated</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Sr Data Scientist, you will be responsibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Data Scientist, Payments</td>\n",
       "      <td>AIRBNB GLOBAL CAPABILITY CENTER PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The Challenge\\nBe a thought leader, partner wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Company  \\\n",
       "0                              Senior Data Scientist   \n",
       "1                              Senior Data Scientist   \n",
       "2  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3                              Senior Data Scientist   \n",
       "4                                  Sr Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7                              Senior Data Scientist   \n",
       "8                              Senior Data Scientist   \n",
       "9                        Sr Data Scientist, Payments   \n",
       "\n",
       "                                        Experience  \\\n",
       "0                                Fractal Analytics   \n",
       "1                                          Nielsen   \n",
       "2                     Wrackle Technologies Pvt Ltd   \n",
       "3   Roppen Transportation Services Private Limited   \n",
       "4                                        NielsenIQ   \n",
       "5                                       Gojek Tech   \n",
       "6                                     GO-JEK India   \n",
       "7                                  Publicis Groupe   \n",
       "8                        Baker Hughes Incorporated   \n",
       "9  AIRBNB GLOBAL CAPABILITY CENTER PRIVATE LIMITED   \n",
       "\n",
       "                                        Location  \\\n",
       "0  Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1         Chennai, Bangalore/Bengaluru, Vadodara   \n",
       "2                            Bangalore/Bengaluru   \n",
       "3                            Bangalore/Bengaluru   \n",
       "4                            Bangalore/Bengaluru   \n",
       "5                            Bangalore/Bengaluru   \n",
       "6                            Bangalore/Bengaluru   \n",
       "7                            Bangalore/Bengaluru   \n",
       "8                            Bangalore/Bengaluru   \n",
       "9                            Bangalore/Bengaluru   \n",
       "\n",
       "                                         Description  \n",
       "0  The Artificial Intelligence and Machine Learni...  \n",
       "1  ABOUT THIS JOB\\nNielsenIQ Advanced Analytics t...  \n",
       "2  Roles and Responsibilities\\nRequirements :\\n\\n...  \n",
       "3  Our Cause:\\nRapido is Indias largest bike taxi...  \n",
       "4  Roles Responsibilities :\\nUnderstand business ...  \n",
       "5  As our Senior Data Scientist, youll be an inte...  \n",
       "6  As our Senior Data Scientist, youll be an inte...  \n",
       "7  Epsilon India team is looking for a talented t...  \n",
       "8  As a Sr Data Scientist, you will be responsibl...  \n",
       "9  The Challenge\\nBe a thought leader, partner wi...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "\n",
    "jobs['Company']=job_Titile\n",
    "jobs['Experience']=job_Company\n",
    "jobs['Location']=job_Location\n",
    "jobs['Description']=job_Description\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-3: In this question you have to scrape data using the filters available on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 ='https://www.naukri.com/'  #set url here\n",
    "driver.get(url3)                  \n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')     #we can find it by id even we can find it with xpath\n",
    "search_job\n",
    "search_job.send_keys(\"Data Scientist\")                         #send on web browser we have to write Data Analyst\n",
    "                     \n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")      #we can find it by id even we can find it with xpath\n",
    "search_btn.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chk_Place=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]')\n",
    "Chk_Place.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chk_salary=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]')\n",
    "Chk_salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Shadowfax Technologies Pvt. Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Change Magician - Machine Learning Engineer</td>\n",
       "      <td>17LIVE INC</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Python, HIVE</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>CYFUTURE INDIA PRIVATE LIMITED</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Noida(NSEZ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Developer - HELI</td>\n",
       "      <td>Blitz Jobs</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Opening For Data Analyst - Business Exc...</td>\n",
       "      <td>Ison Bpo India Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - BI</td>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>ADHIKARI PLACEMENTS SERVICES( OPC) PRIVATE LIM...</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python Developer - Gurgaon</td>\n",
       "      <td>Elizabeth N Queen</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0              Chaayos is Looking For Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2        Change Magician - Machine Learning Engineer   \n",
       "3                        Data Analyst - Python, HIVE   \n",
       "4                                   Python Developer   \n",
       "5                            Python Developer - HELI   \n",
       "6  Urgent Opening For Data Analyst - Business Exc...   \n",
       "7                                  Data Analyst - BI   \n",
       "8                                   Python Developer   \n",
       "9                         Python Developer - Gurgaon   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "0              Chaayos (Sunshine Teahouse Pvt. Ltd.)    0-5 Yrs   \n",
       "1                   Shadowfax Technologies Pvt. Ltd.    1-3 Yrs   \n",
       "2                                         17LIVE INC    0-0 Yrs   \n",
       "3     Optum Global Solutions (India) Private Limited    1-4 Yrs   \n",
       "4                     CYFUTURE INDIA PRIVATE LIMITED    1-4 Yrs   \n",
       "5                                         Blitz Jobs    1-3 Yrs   \n",
       "6                             Ison Bpo India Pvt Ltd    2-5 Yrs   \n",
       "7             AlgoScale Technologies Private Limited    2-5 Yrs   \n",
       "8  ADHIKARI PLACEMENTS SERVICES( OPC) PRIVATE LIM...    1-3 Yrs   \n",
       "9                                  Elizabeth N Queen    2-4 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0                                          New Delhi  \n",
       "1                                   Gurgaon/Gurugram  \n",
       "2  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...  \n",
       "3                                              Noida  \n",
       "4                                        Noida(NSEZ)  \n",
       "5                                   Gurgaon/Gurugram  \n",
       "6                                              Noida  \n",
       "7               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "8              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "9                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Titile\n",
    "Titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "job_titles=[]              #empty tag \n",
    "for i in Titles_tags:      \n",
    "    job_titles.append(i.text)\n",
    "\n",
    "job_titles \n",
    "#Experience_tags\n",
    "Experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "Experience_tags\n",
    "job_exp=[]\n",
    "for i in Experience_tags:\n",
    "    job_exp.append(i.text)\n",
    "job_exp \n",
    "\n",
    "#salary_tags\n",
    "salary_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']//span\")\n",
    "salary_tags\n",
    "#Now we will run for loop to find all data\n",
    "salary_exp=[]\n",
    "for i in salary_tags:\n",
    "    salary_exp.append(i.text)\n",
    "salary_exp \n",
    "\n",
    "#desrcriptionTag\n",
    "desrcriptionTag=driver.find_elements_by_xpath(\"//div[@class='job-description fs12 grey-text']\")\n",
    "desrcriptionTag\n",
    "descriptionJob=[]\n",
    "for i in desrcriptionTag:\n",
    "    descriptionJob.append(i.text)\n",
    "descriptionJob\n",
    "\n",
    "#locationJob\n",
    "locationJob=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "locationJob\n",
    "locationForJob=[]\n",
    "for i in locationJob:\n",
    "    locationForJob.append(i.text)\n",
    "locationForJob\n",
    "\n",
    "#Company\n",
    "Companytags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "Companytags\n",
    "#Now we will run for loop to find all data\n",
    "job_Company=[]              #empty tag \n",
    "for i in Companytags:      \n",
    "    job_Company.append(i.text)\n",
    "\n",
    "job_Company \n",
    "print(len(job_titles),len(job_exp),len(salary_exp),len(job_Company),len(locationForJob))\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Company']=job_Company\n",
    "jobs['Experience']=job_exp\n",
    "jobs['Location']=locationForJob\n",
    "jobs[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the compan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 ='https://www.glassdoor.co.in/index.htm'  #set url here\n",
    "driver.get(url4)                  \n",
    "search_job=driver.find_element_by_id('sc.keyword')     #we can find it by id even we can find it with xpath\n",
    "search_job\n",
    "search_job.send_keys(\"Data Scientist\")                         #send on web browser we have to write Data Analyst\n",
    "         \n",
    "search_job=driver.find_element_by_id('sc.location')     #we can find it by id even we can find it with xpath\n",
    "search_job\n",
    "search_job.send_keys(\"Noida\")      \n",
    "search_btn=driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button')      #we can find it by id even we can find it with xpath\n",
    "search_btn.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ericsson',\n",
       " 'MasterCard',\n",
       " 'Siemens Technology and Services Private Limited',\n",
       " 'CSTEP',\n",
       " 'Crowe',\n",
       " 'Ginger Webs Pvt. Ltd.',\n",
       " 'Data Patterns',\n",
       " 'UnitedHealth Group',\n",
       " 'Innovacer',\n",
       " 'Scymes Services Pvt. ltd']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Titles_tags=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a[@class=' css-l2wjgv e1n63ojh0 jobLink']//span\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "job_titles=[]              #empty tag \n",
    "for i in Titles_tags[:10]:\n",
    "     job_titles.append(i.text)  \n",
    "job_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '4.3', '4.1', '3.1', '3.8', '3.0', '3.7', '3.8', '3.9', '4.1']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Titles_tags=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "job_star=[]              #empty tag \n",
    "for i in Titles_tags[:10]:\n",
    "     job_star.append(i.text)  \n",
    "job_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1d', '1d', '14d', '17d', '30d', '22d', '18d', '3d', '4d', '24h']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Titles_tags=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "job_day=[]              #empty tag \n",
    "for i in Titles_tags[:10]:\n",
    "     job_day.append(i.text)  \n",
    "job_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>rate</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MasterCard</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSTEP</td>\n",
       "      <td>3.1</td>\n",
       "      <td>17d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ginger Webs Pvt. Ltd.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Patterns</td>\n",
       "      <td>3.7</td>\n",
       "      <td>18d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Innovacer</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scymes Services Pvt. ltd</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title rate days\n",
       "0                                         Ericsson  4.1   1d\n",
       "1                                       MasterCard  4.3   1d\n",
       "2  Siemens Technology and Services Private Limited  4.1  14d\n",
       "3                                            CSTEP  3.1  17d\n",
       "4                                            Crowe  3.8  30d\n",
       "5                            Ginger Webs Pvt. Ltd.  3.0  22d\n",
       "6                                    Data Patterns  3.7  18d\n",
       "7                               UnitedHealth Group  3.8   3d\n",
       "8                                        Innovacer  3.9   4d\n",
       "9                         Scymes Services Pvt. ltd  4.1  24h"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['rate']=job_star\n",
    "jobs['days']=job_day\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note: I used location SURAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 =' https://www.glassdoor.co.in/Salaries/index.htm'  #set url here\n",
    "driver.get(url5)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id('KeywordSearch')     #we can find it by id even we can find it with xpath\n",
    "search_job\n",
    "search_job.send_keys(\"Data Scientist\")                         #send on web browser we have to write Data Analyst\n",
    "         \n",
    "search_job=driver.find_element_by_id('LocationSearch')     #we can find it by id even we can find it with xpath\n",
    "search_job\n",
    "search_job.send_keys(\"Surat (India)\")      \n",
    "search_btn=driver.find_element_by_xpath('//*[@id=\"HeroSearchButton\"]')      #we can find it by id even we can find it with xpath\n",
    "search_btn.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM',\n",
       " 'Tata Consultancy Services',\n",
       " 'Accenture',\n",
       " 'Delhivery',\n",
       " 'Ericsson-Worldwide',\n",
       " 'UnitedHealth Group',\n",
       " 'Valiance Solutions',\n",
       " 'EXL Service',\n",
       " 'Optum Global Solutions',\n",
       " 'ZS Associates']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles_tags=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "job_titles=[]              #empty tag \n",
    "for i in Titles_tags[:10]:\n",
    "     job_titles.append(i.text)  \n",
    "job_titles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9', '3.9', '4', '3.9', '4', '3.7', '4.2', '3.6', '3.9', '4']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles_tags=driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "job_star=[]              #empty tag \n",
    "for i in Titles_tags[:10]:\n",
    "     job_star.append(i.text)  \n",
    "job_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"996adf5b-97cb-4dad-ac91-44656a5503b1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"20549dec-a27b-46e7-be97-7919c62d87f0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"1121d4fe-0636-484e-94c3-6d3b1b68b220\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"b98850bc-2685-47f8-a7eb-4e2721d9b311\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"42255d5c-6c72-445a-bc45-af35e0119b31\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"079de790-7755-4c4b-a2fe-991043b8b1d9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"8f618a76-e987-43f0-bc78-7bac4f56fb71\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"be180109-0d22-4130-bdf0-be8744953adf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"c6a74593-193c-4839-a20c-23c6c7b69e60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"22810084-c3a2-4a64-9b7e-5c1ac0af94e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"16d2f882-1233-4bb9-97a8-1e4af5e36316\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"5bfd75dd-0da8-4730-bf19-a5168a5ec4e2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"7c293348-ef62-43bc-9783-ebe166d5175d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"e4ff9432-4355-439a-9077-22af6a3102f2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"90bd7ab3-341b-49f8-838a-f56995470d3d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"2aa4615b-9888-46b7-990c-d8537fb1ff54\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"480ccee2-e90e-4ac4-aa63-879531d720b4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"ef30394b-800e-4a26-9a8b-b0922123ada0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"8d86b9d5-a3c1-4d45-91a9-cea3ae30e8ff\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"98a8a4562b672b412cedcf083a456bb6\", element=\"c4507181-d588-4e13-a967-339cc091ef2d\")>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles_tags=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "Titles_tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹9,00,000\\n /yr',\n",
       " '₹6,15,289\\n /yr',\n",
       " '₹11,63,336\\n /yr',\n",
       " '₹12,18,244\\n /yr',\n",
       " '₹7,39,238\\n /yr',\n",
       " '₹13,00,000\\n /yr',\n",
       " '₹8,63,750\\n /yr',\n",
       " '₹11,10,000\\n /yr',\n",
       " '₹13,28,697\\n /yr',\n",
       " '₹11,42,356\\n /yr']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we will run for loop to find all data\n",
    "avrage_salary=[]              #empty tag \n",
    "for i in Titles_tags[:10]:\n",
    "     avrage_salary.append(i.text) \n",
    "avrage_salary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles_tags=driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0'][1]\")\n",
    "Titles_tags\n",
    "#Now we will run for loop to find all data\n",
    "min_salary=[]              #empty tag \n",
    "for i in Titles_tags[:10]:\n",
    "    try:\n",
    "        min_salary.append(i.text).replace('\\n','')\n",
    "    except:\n",
    "        pass\n",
    "min_salary\n",
    "#note: \\n is how can I remove here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>rate</th>\n",
       "      <th>avrage salary</th>\n",
       "      <th>Min -Max salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹9,00,000\\n /yr</td>\n",
       "      <td>₹6L\\n₹27L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹27L</td>\n",
       "      <td>₹6,15,289\\n /yr</td>\n",
       "      <td>₹3L\\n₹13L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>₹11,63,336\\n /yr</td>\n",
       "      <td>₹6L\\n₹22L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹12,18,244\\n /yr</td>\n",
       "      <td>₹5L\\n₹1Cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹7,39,238\\n /yr</td>\n",
       "      <td>₹4L\\n₹16L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹13,00,000\\n /yr</td>\n",
       "      <td>₹8L\\n₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹8,63,750\\n /yr</td>\n",
       "      <td>₹5L\\n₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹11,10,000\\n /yr</td>\n",
       "      <td>₹6L\\n₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13,28,697\\n /yr</td>\n",
       "      <td>₹4L\\n₹22L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹11,42,356\\n /yr</td>\n",
       "      <td>₹2L\\n₹18L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  rate     avrage salary Min -Max salary\n",
       "0                        IBM   ₹6L   ₹9,00,000\\n /yr       ₹6L\\n₹27L\n",
       "1  Tata Consultancy Services  ₹27L   ₹6,15,289\\n /yr       ₹3L\\n₹13L\n",
       "2                  Accenture   ₹3L  ₹11,63,336\\n /yr       ₹6L\\n₹22L\n",
       "3                  Delhivery  ₹13L  ₹12,18,244\\n /yr       ₹5L\\n₹1Cr\n",
       "4         Ericsson-Worldwide   ₹6L   ₹7,39,238\\n /yr       ₹4L\\n₹16L\n",
       "5         UnitedHealth Group  ₹22L  ₹13,00,000\\n /yr       ₹8L\\n₹15L\n",
       "6         Valiance Solutions   ₹5L   ₹8,63,750\\n /yr       ₹5L\\n₹15L\n",
       "7                EXL Service  ₹1Cr  ₹11,10,000\\n /yr       ₹6L\\n₹15L\n",
       "8     Optum Global Solutions   ₹4L  ₹13,28,697\\n /yr       ₹4L\\n₹22L\n",
       "9              ZS Associates  ₹16L  ₹11,42,356\\n /yr       ₹2L\\n₹18L"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['rate']=job_star\n",
    "jobs['avrage salary']=avrage_salary\n",
    "jobs['Min -Max salary']=min_salary\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url6 ='https://www.flipkart.com/'  #set url here\n",
    "driver.get(url6)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')     #we can find it by id even we can find it with xpath\n",
    "search\n",
    "search.send_keys(\"sunglasses\")                         #send on web browser we have to write Data Analyst\n",
    "         \n",
    "search_btn=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')      #we can find it by id even we can find it with xpath\n",
    "search_btn.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fravy',\n",
       " 'PHENOMENAL',\n",
       " 'Fastrack',\n",
       " 'kingsunglasses',\n",
       " 'Fastrack',\n",
       " 'Badfella',\n",
       " 'Fastrack',\n",
       " 'Villain',\n",
       " 'Singco India',\n",
       " 'PIRASO',\n",
       " 'Fastrack',\n",
       " 'NuVew',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Silver Kartz',\n",
       " 'Wrogn',\n",
       " 'kingsunglasses',\n",
       " 'NuVew',\n",
       " 'Elligator',\n",
       " 'ROYAL SON',\n",
       " 'PHENOMENAL',\n",
       " 'kingsunglasses',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'Poloport',\n",
       " 'ROYAL SON',\n",
       " 'Fastrack',\n",
       " 'GANSTA',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'hipe',\n",
       " 'United Colors of Benetton',\n",
       " 'ROYAL SON',\n",
       " 'GANSTA',\n",
       " 'IRUS by IDEE',\n",
       " 'AISLIN',\n",
       " 'Flizz',\n",
       " 'hipe',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fravy',\n",
       " 'PHENOMENAL',\n",
       " 'Fastrack',\n",
       " 'kingsunglasses',\n",
       " 'Fastrack',\n",
       " 'Badfella',\n",
       " 'Fastrack',\n",
       " 'Villain',\n",
       " 'Singco India',\n",
       " 'PIRASO',\n",
       " 'Fastrack',\n",
       " 'NuVew',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Silver Kartz',\n",
       " 'Wrogn',\n",
       " 'kingsunglasses',\n",
       " 'NuVew',\n",
       " 'Elligator',\n",
       " 'ROYAL SON',\n",
       " 'PHENOMENAL',\n",
       " 'kingsunglasses',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'Poloport',\n",
       " 'ROYAL SON',\n",
       " 'Fastrack',\n",
       " 'GANSTA',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'hipe',\n",
       " 'United Colors of Benetton',\n",
       " 'ROYAL SON',\n",
       " 'GANSTA',\n",
       " 'IRUS by IDEE',\n",
       " 'AISLIN',\n",
       " 'Flizz',\n",
       " 'hipe',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fravy',\n",
       " 'PHENOMENAL',\n",
       " 'Fastrack',\n",
       " 'kingsunglasses',\n",
       " 'Fastrack',\n",
       " 'Badfella',\n",
       " 'Fastrack',\n",
       " 'Villain',\n",
       " 'Singco India',\n",
       " 'PIRASO',\n",
       " 'Fastrack',\n",
       " 'NuVew',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Silver Kartz',\n",
       " 'Wrogn',\n",
       " 'kingsunglasses',\n",
       " 'NuVew',\n",
       " 'Elligator',\n",
       " 'ROYAL SON']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "product_titles=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_titles.append(i.text) \n",
    "product_titles[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_titles[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'UV Protection, Mirrored Clubmaster Sunglasses (Free Siz...',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Rectangular Sunglasses (55)',\n",
       " 'UV Protection Wayfarer Sunglasses (55)',\n",
       " 'Polarized, UV Protection Retro Square Sunglasses (53)',\n",
       " 'Gradient Aviator Sunglasses (Free Size)',\n",
       " 'Others Retro Square Sunglasses (Free Size)',\n",
       " 'Riding Glasses, UV Protection, Others Aviator Sunglasse...',\n",
       " 'UV Protection Wayfarer Sunglasses (32)',\n",
       " 'UV Protection Rectangular Sunglasses (59)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection, Polarized, Riding Glasses Oval Sunglasse...',\n",
       " 'UV Protection Oval Sunglasses (56)',\n",
       " 'Mirrored Retro Square Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Aviator Sunglasses (56)',\n",
       " 'UV Protection, Riding Glasses Wayfarer Sunglasses (56)',\n",
       " 'UV Protection, Riding Glasses Rectangular, Retro Square...',\n",
       " 'UV Protection Wayfarer Sunglasses (55)',\n",
       " 'UV Protection, Mirrored, Gradient Retro Square Sunglass...',\n",
       " 'UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection Wrap-around Sunglasses (Free Size)',\n",
       " 'UV Protection, Mirrored Wayfarer Sunglasses (61)',\n",
       " 'Gradient Round Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer Sunglasses (57)',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Retro Square Sunglasses (58)',\n",
       " 'UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'UV Protection Rectangular Sunglasses (Free Size)',\n",
       " 'UV Protection, Night Vision, Riding Glasses, Gradient, ...',\n",
       " 'Mirrored, UV Protection Rectangular Sunglasses (56)',\n",
       " 'UV Protection Retro Square Sunglasses (58)',\n",
       " 'UV Protection, Gradient Wayfarer Sunglasses (53)',\n",
       " 'Others Rectangular Sunglasses (56)',\n",
       " 'UV Protection, Gradient Butterfly, Retro Square Sunglas...',\n",
       " 'UV Protection, Polarized Rectangular Sunglasses (Free S...',\n",
       " 'UV Protection, Gradient, Riding Glasses Wayfarer Sungla...',\n",
       " 'Polarized, UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'UV Protection, Mirrored Clubmaster Sunglasses (Free Siz...',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Rectangular Sunglasses (55)',\n",
       " 'UV Protection Wayfarer Sunglasses (55)',\n",
       " 'Polarized, UV Protection Retro Square Sunglasses (53)',\n",
       " 'Gradient Aviator Sunglasses (Free Size)',\n",
       " 'Others Retro Square Sunglasses (Free Size)',\n",
       " 'Riding Glasses, UV Protection, Others Aviator Sunglasse...',\n",
       " 'UV Protection Wayfarer Sunglasses (32)',\n",
       " 'UV Protection Rectangular Sunglasses (59)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection, Polarized, Riding Glasses Oval Sunglasse...',\n",
       " 'UV Protection Oval Sunglasses (56)',\n",
       " 'Mirrored Retro Square Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Aviator Sunglasses (56)',\n",
       " 'UV Protection, Riding Glasses Wayfarer Sunglasses (56)',\n",
       " 'UV Protection, Riding Glasses Rectangular, Retro Square...',\n",
       " 'UV Protection Wayfarer Sunglasses (55)',\n",
       " 'UV Protection, Mirrored, Gradient Retro Square Sunglass...',\n",
       " 'UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection Wrap-around Sunglasses (Free Size)',\n",
       " 'UV Protection, Mirrored Wayfarer Sunglasses (61)',\n",
       " 'Gradient Round Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer Sunglasses (57)',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Retro Square Sunglasses (58)',\n",
       " 'UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'UV Protection Rectangular Sunglasses (Free Size)',\n",
       " 'UV Protection, Night Vision, Riding Glasses, Gradient, ...',\n",
       " 'Mirrored, UV Protection Rectangular Sunglasses (56)',\n",
       " 'UV Protection Retro Square Sunglasses (58)',\n",
       " 'UV Protection, Gradient Wayfarer Sunglasses (53)',\n",
       " 'Others Rectangular Sunglasses (56)',\n",
       " 'UV Protection, Gradient Butterfly, Retro Square Sunglas...',\n",
       " 'UV Protection, Polarized Rectangular Sunglasses (Free S...',\n",
       " 'UV Protection, Gradient, Riding Glasses Wayfarer Sungla...',\n",
       " 'Polarized, UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'UV Protection, Mirrored Clubmaster Sunglasses (Free Siz...',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Rectangular Sunglasses (55)',\n",
       " 'UV Protection Wayfarer Sunglasses (55)',\n",
       " 'Polarized, UV Protection Retro Square Sunglasses (53)',\n",
       " 'Gradient Aviator Sunglasses (Free Size)',\n",
       " 'Others Retro Square Sunglasses (Free Size)',\n",
       " 'Riding Glasses, UV Protection, Others Aviator Sunglasse...',\n",
       " 'UV Protection Wayfarer Sunglasses (32)',\n",
       " 'UV Protection Rectangular Sunglasses (59)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection, Polarized, Riding Glasses Oval Sunglasse...',\n",
       " 'UV Protection Oval Sunglasses (56)',\n",
       " 'Mirrored Retro Square Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Aviator Sunglasses (56)',\n",
       " 'UV Protection, Riding Glasses Wayfarer Sunglasses (56)',\n",
       " 'UV Protection, Riding Glasses Rectangular, Retro Square...',\n",
       " 'UV Protection Wayfarer Sunglasses (55)']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_desc=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_desc.append(i.text) \n",
    "product_desc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_desc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹299',\n",
       " '₹319',\n",
       " '₹782',\n",
       " '₹210',\n",
       " '₹575',\n",
       " '₹269',\n",
       " '₹1,830',\n",
       " '₹539',\n",
       " '₹227',\n",
       " '₹237',\n",
       " '₹1,021',\n",
       " '₹185',\n",
       " '₹399',\n",
       " '₹1,470',\n",
       " '₹299',\n",
       " '₹711',\n",
       " '₹249',\n",
       " '₹235',\n",
       " '₹443',\n",
       " '₹265',\n",
       " '₹259',\n",
       " '₹315',\n",
       " '₹738',\n",
       " '₹788',\n",
       " '₹1,969',\n",
       " '₹503',\n",
       " '₹331',\n",
       " '₹499',\n",
       " '₹627',\n",
       " '₹323',\n",
       " '₹398',\n",
       " '₹197',\n",
       " '₹1,222',\n",
       " '₹499',\n",
       " '₹314',\n",
       " '₹454',\n",
       " '₹545',\n",
       " '₹279',\n",
       " '₹249',\n",
       " '₹449',\n",
       " '₹299',\n",
       " '₹319',\n",
       " '₹782',\n",
       " '₹210',\n",
       " '₹575',\n",
       " '₹269',\n",
       " '₹1,830',\n",
       " '₹539',\n",
       " '₹227',\n",
       " '₹237',\n",
       " '₹1,021',\n",
       " '₹185',\n",
       " '₹399',\n",
       " '₹1,470',\n",
       " '₹299',\n",
       " '₹711',\n",
       " '₹249',\n",
       " '₹235',\n",
       " '₹443',\n",
       " '₹265',\n",
       " '₹259',\n",
       " '₹315',\n",
       " '₹738',\n",
       " '₹788',\n",
       " '₹1,969',\n",
       " '₹503',\n",
       " '₹331',\n",
       " '₹499',\n",
       " '₹627',\n",
       " '₹323',\n",
       " '₹398',\n",
       " '₹197',\n",
       " '₹1,222',\n",
       " '₹499',\n",
       " '₹314',\n",
       " '₹454',\n",
       " '₹545',\n",
       " '₹279',\n",
       " '₹249',\n",
       " '₹449',\n",
       " '₹299',\n",
       " '₹319',\n",
       " '₹782',\n",
       " '₹210',\n",
       " '₹575',\n",
       " '₹269',\n",
       " '₹1,830',\n",
       " '₹539',\n",
       " '₹227',\n",
       " '₹237',\n",
       " '₹1,021',\n",
       " '₹185',\n",
       " '₹399',\n",
       " '₹1,470',\n",
       " '₹299',\n",
       " '₹711',\n",
       " '₹249',\n",
       " '₹235',\n",
       " '₹443',\n",
       " '₹265']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_price=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_price.append(i.text) \n",
    "product_price[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_price[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['80% off',\n",
       " '84% off',\n",
       " '₹17 off',\n",
       " '83% off',\n",
       " '₹224 off',\n",
       " '73% off',\n",
       " '₹169 off',\n",
       " '₹211 off',\n",
       " '84% off',\n",
       " '85% off',\n",
       " '₹278 off',\n",
       " '75% off',\n",
       " '72% off',\n",
       " '26% off',\n",
       " '75% off',\n",
       " '72% off',\n",
       " '80% off',\n",
       " '75% off',\n",
       " '70% off',\n",
       " '79% off',\n",
       " '87% off',\n",
       " '81% off',\n",
       " '₹361 off',\n",
       " '₹111 off',\n",
       " '₹30 off',\n",
       " '₹296 off',\n",
       " '81% off',\n",
       " '66% off',\n",
       " '₹272 off',\n",
       " '83% off',\n",
       " '73% off',\n",
       " '84% off',\n",
       " '70% off',\n",
       " '66% off',\n",
       " '84% off',\n",
       " '64% off',\n",
       " '64% off',\n",
       " '81% off',\n",
       " '75% off',\n",
       " '77% off',\n",
       " '80% off',\n",
       " '84% off',\n",
       " '₹17 off',\n",
       " '83% off',\n",
       " '₹224 off',\n",
       " '73% off',\n",
       " '₹169 off',\n",
       " '₹211 off',\n",
       " '84% off',\n",
       " '85% off',\n",
       " '₹278 off',\n",
       " '75% off',\n",
       " '72% off',\n",
       " '26% off',\n",
       " '75% off',\n",
       " '72% off',\n",
       " '80% off',\n",
       " '75% off',\n",
       " '70% off',\n",
       " '79% off',\n",
       " '87% off',\n",
       " '81% off',\n",
       " '₹361 off',\n",
       " '₹111 off',\n",
       " '₹30 off',\n",
       " '₹296 off',\n",
       " '81% off',\n",
       " '66% off',\n",
       " '₹272 off',\n",
       " '83% off',\n",
       " '73% off',\n",
       " '84% off',\n",
       " '70% off',\n",
       " '66% off',\n",
       " '84% off',\n",
       " '64% off',\n",
       " '64% off',\n",
       " '81% off',\n",
       " '75% off',\n",
       " '77% off',\n",
       " '80% off',\n",
       " '84% off',\n",
       " '₹17 off',\n",
       " '83% off',\n",
       " '₹224 off',\n",
       " '73% off',\n",
       " '₹169 off',\n",
       " '₹211 off',\n",
       " '84% off',\n",
       " '85% off',\n",
       " '₹278 off',\n",
       " '75% off',\n",
       " '72% off',\n",
       " '26% off',\n",
       " '75% off',\n",
       " '72% off',\n",
       " '80% off',\n",
       " '75% off',\n",
       " '70% off',\n",
       " '79% off']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_disc=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_disc.append(i.text) \n",
    "product_disc[:100]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_disc[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored Clubmaster Sunglasses ...</td>\n",
       "      <td>₹319</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹782</td>\n",
       "      <td>₹17 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (55)</td>\n",
       "      <td>₹210</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹575</td>\n",
       "      <td>₹224 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Mirrored Retro Square Sunglasses (57)</td>\n",
       "      <td>₹711</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (56)</td>\n",
       "      <td>₹249</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Riding Glasses Wayfarer Sunglas...</td>\n",
       "      <td>₹235</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection, Riding Glasses Rectangular, Ret...</td>\n",
       "      <td>₹443</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹265</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                        Description Price  \\\n",
       "0            Fravy  UV Protection Retro Square Sunglasses (Free Size)  ₹299   \n",
       "1       PHENOMENAL  UV Protection, Mirrored Clubmaster Sunglasses ...  ₹319   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹782   \n",
       "3   kingsunglasses          UV Protection Rectangular Sunglasses (55)  ₹210   \n",
       "4         Fastrack             UV Protection Wayfarer Sunglasses (55)  ₹575   \n",
       "..             ...                                                ...   ...   \n",
       "95           Wrogn              Mirrored Retro Square Sunglasses (57)  ₹711   \n",
       "96  kingsunglasses    Mirrored, UV Protection Aviator Sunglasses (56)  ₹249   \n",
       "97           NuVew  UV Protection, Riding Glasses Wayfarer Sunglas...  ₹235   \n",
       "98       Elligator  UV Protection, Riding Glasses Rectangular, Ret...  ₹443   \n",
       "99       ROYAL SON             UV Protection Wayfarer Sunglasses (55)  ₹265   \n",
       "\n",
       "   Discounts  \n",
       "0    80% off  \n",
       "1    84% off  \n",
       "2    ₹17 off  \n",
       "3    83% off  \n",
       "4   ₹224 off  \n",
       "..       ...  \n",
       "95   72% off  \n",
       "96   80% off  \n",
       "97   75% off  \n",
       "98   70% off  \n",
       "99   79% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "products=pd.DataFrame({})\n",
    "products['Name']=product_titles[:100]\n",
    "products['Description']=product_desc[:100]\n",
    "products['Price']=product_price[:100]\n",
    "products['Discounts']=product_disc[:100]\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url6 ='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.¶'  #set url here\n",
    "driver.get(url6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=1',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=2',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=3']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "Titles\n",
    "product_url=[]              #empty tag \n",
    "for i in Titles[:3]:\n",
    "     product_url.append(i.get_attribute('href')) \n",
    "product_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '5',\n",
       " '5',\n",
       " '5']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "product_titles=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_titles.append(i.text) \n",
    "product_titles[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_titles[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Best Phone for the Money\\n\\nThe iPhone 11 offers superb cameras, a more durable design and excellent battery life for an affordable price.\\n\\nCompelling ultra-wide camera\\nNew Night mode is excellent\\nLong battery life',\n",
       " 'Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .',\n",
       " 'Previously I was using one plus 3t it was a great phone\\nAnd then I decided to upgrade I am stuck between Samsung s10 plus or iPhone 11\\nI have seen the specs and everything were good except the display it’s somewhere between 720-1080 and it’s not even an amoled it’s an LCD display\\nBut I decided to go with iPhone because I have never used an IOS device I have Been an android user from the past 9 years I ordered IPhone 11 (128gb) product red\\nMy experience after using 3 weeks\\n1. The delivery ...',\n",
       " 'This is my first iOS phone. I am very happy with this product. Very much satisfied with this. I love this phone.',\n",
       " 'Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.',\n",
       " 'Amazing Powerful and Durable Gadget.\\n\\nI’m am very happy with the camera picture quality, Amazing face id unlocked in dark room, Strong battery with perfect screen size as you can carry easily in pocket. This is my third iPhone.\\n\\nI shifted from android Samsung Note series to iPhone because of the strong build quality and peace of mind for next 3-4 years.\\n\\nDon’t think to much just go for it and I suggest you to go for minimum 128gb variant or more 256gb.\\n\\nI’ve attached my puppy pics and no fi...',\n",
       " 'So far it’s been an AMAZING experience coming back to iOS after nearly a decade but it’s not as versatile as android though phone is sturdy dropped it accidentally a couple of times and nothing happened fortunately camera is awesome',\n",
       " 'i11 is worthy to buy, too much happy with the product. Thank u flipkart I received the item on time..loved it..',\n",
       " 'iphone 11 is a very good phone to buy only if you can compromise for the display. The display on this is device is pretty good but you can get other options with better displays in this price segment.\\nIf you can survive with an HD+ LCD panel with thicker bezels and a notch up top then this is a very good phone for you.\\nCameras are awesome, battery backup excellent, great performance and a decent premium look. Good job Apple !',\n",
       " 'It’s a must buy who is looking for an upgrade from previous generation of iPhones. If you are using XR then still you can hold on for sometime and upgrade to 2020 model else this phone is a must buy . Camera quality is amazing and wide angle is something to count upon. Performance wise it’s amazing and feels premium while holding in hand. So a big YES for this device. Go for 128 GB variant as the 4K videos will occupy lots of space and the storage can get over very quickly. Try to buy it with...',\n",
       " 'The Best Phone for the Money\\n\\nThe iPhone 11 offers superb cameras, a more durable design and excellent battery life for an affordable price.\\n\\nCompelling ultra-wide camera\\nNew Night mode is excellent\\nLong battery life',\n",
       " 'Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .',\n",
       " 'Previously I was using one plus 3t it was a great phone\\nAnd then I decided to upgrade I am stuck between Samsung s10 plus or iPhone 11\\nI have seen the specs and everything were good except the display it’s somewhere between 720-1080 and it’s not even an amoled it’s an LCD display\\nBut I decided to go with iPhone because I have never used an IOS device I have Been an android user from the past 9 years I ordered IPhone 11 (128gb) product red\\nMy experience after using 3 weeks\\n1. The delivery ...',\n",
       " 'This is my first iOS phone. I am very happy with this product. Very much satisfied with this. I love this phone.',\n",
       " 'Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.',\n",
       " 'Amazing Powerful and Durable Gadget.\\n\\nI’m am very happy with the camera picture quality, Amazing face id unlocked in dark room, Strong battery with perfect screen size as you can carry easily in pocket. This is my third iPhone.\\n\\nI shifted from android Samsung Note series to iPhone because of the strong build quality and peace of mind for next 3-4 years.\\n\\nDon’t think to much just go for it and I suggest you to go for minimum 128gb variant or more 256gb.\\n\\nI’ve attached my puppy pics and no fi...',\n",
       " 'So far it’s been an AMAZING experience coming back to iOS after nearly a decade but it’s not as versatile as android though phone is sturdy dropped it accidentally a couple of times and nothing happened fortunately camera is awesome',\n",
       " 'i11 is worthy to buy, too much happy with the product. Thank u flipkart I received the item on time..loved it..',\n",
       " 'iphone 11 is a very good phone to buy only if you can compromise for the display. The display on this is device is pretty good but you can get other options with better displays in this price segment.\\nIf you can survive with an HD+ LCD panel with thicker bezels and a notch up top then this is a very good phone for you.\\nCameras are awesome, battery backup excellent, great performance and a decent premium look. Good job Apple !',\n",
       " 'It’s a must buy who is looking for an upgrade from previous generation of iPhones. If you are using XR then still you can hold on for sometime and upgrade to 2020 model else this phone is a must buy . Camera quality is amazing and wide angle is something to count upon. Performance wise it’s amazing and feels premium while holding in hand. So a big YES for this device. Go for 128 GB variant as the 4K videos will occupy lots of space and the storage can get over very quickly. Try to buy it with...',\n",
       " 'The Best Phone for the Money\\n\\nThe iPhone 11 offers superb cameras, a more durable design and excellent battery life for an affordable price.\\n\\nCompelling ultra-wide camera\\nNew Night mode is excellent\\nLong battery life',\n",
       " 'Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .',\n",
       " 'Previously I was using one plus 3t it was a great phone\\nAnd then I decided to upgrade I am stuck between Samsung s10 plus or iPhone 11\\nI have seen the specs and everything were good except the display it’s somewhere between 720-1080 and it’s not even an amoled it’s an LCD display\\nBut I decided to go with iPhone because I have never used an IOS device I have Been an android user from the past 9 years I ordered IPhone 11 (128gb) product red\\nMy experience after using 3 weeks\\n1. The delivery ...',\n",
       " 'This is my first iOS phone. I am very happy with this product. Very much satisfied with this. I love this phone.',\n",
       " 'Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.',\n",
       " 'Amazing Powerful and Durable Gadget.\\n\\nI’m am very happy with the camera picture quality, Amazing face id unlocked in dark room, Strong battery with perfect screen size as you can carry easily in pocket. This is my third iPhone.\\n\\nI shifted from android Samsung Note series to iPhone because of the strong build quality and peace of mind for next 3-4 years.\\n\\nDon’t think to much just go for it and I suggest you to go for minimum 128gb variant or more 256gb.\\n\\nI’ve attached my puppy pics and no fi...',\n",
       " 'So far it’s been an AMAZING experience coming back to iOS after nearly a decade but it’s not as versatile as android though phone is sturdy dropped it accidentally a couple of times and nothing happened fortunately camera is awesome',\n",
       " 'i11 is worthy to buy, too much happy with the product. Thank u flipkart I received the item on time..loved it..',\n",
       " 'iphone 11 is a very good phone to buy only if you can compromise for the display. The display on this is device is pretty good but you can get other options with better displays in this price segment.\\nIf you can survive with an HD+ LCD panel with thicker bezels and a notch up top then this is a very good phone for you.\\nCameras are awesome, battery backup excellent, great performance and a decent premium look. Good job Apple !',\n",
       " 'It’s a must buy who is looking for an upgrade from previous generation of iPhones. If you are using XR then still you can hold on for sometime and upgrade to 2020 model else this phone is a must buy . Camera quality is amazing and wide angle is something to count upon. Performance wise it’s amazing and feels premium while holding in hand. So a big YES for this device. Go for 128 GB variant as the 4K videos will occupy lots of space and the storage can get over very quickly. Try to buy it with...']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "product_review=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_review.append(i.text) \n",
    "product_review[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brilliant',\n",
       " 'Perfect product!',\n",
       " 'Worth every penny',\n",
       " 'Fabulous!',\n",
       " 'Simply awesome',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Perfect product!',\n",
       " 'Brilliant',\n",
       " 'Perfect product!',\n",
       " 'Worth every penny',\n",
       " 'Fabulous!',\n",
       " 'Simply awesome',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Perfect product!',\n",
       " 'Brilliant',\n",
       " 'Perfect product!',\n",
       " 'Worth every penny',\n",
       " 'Fabulous!',\n",
       " 'Simply awesome',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Perfect product!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_summary=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_summary.append(i.text) \n",
    "product_summary[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_titles[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating             Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5   Worth every penny   \n",
       "3       5           Fabulous!   \n",
       "4       5      Simply awesome   \n",
       "5       5       Great product   \n",
       "6       4         Good choice   \n",
       "7       5   Worth every penny   \n",
       "8       5  Highly recommended   \n",
       "9       5    Perfect product!   \n",
       "10      5           Brilliant   \n",
       "11      5    Perfect product!   \n",
       "12      5   Worth every penny   \n",
       "13      5           Fabulous!   \n",
       "14      5      Simply awesome   \n",
       "15      5       Great product   \n",
       "16      4         Good choice   \n",
       "17      5   Worth every penny   \n",
       "18      5  Highly recommended   \n",
       "19      5    Perfect product!   \n",
       "20      5           Brilliant   \n",
       "21      5    Perfect product!   \n",
       "22      5   Worth every penny   \n",
       "23      5           Fabulous!   \n",
       "24      5      Simply awesome   \n",
       "25      5       Great product   \n",
       "26      4         Good choice   \n",
       "27      5   Worth every penny   \n",
       "28      5  Highly recommended   \n",
       "29      5    Perfect product!   \n",
       "\n",
       "                                          Description  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   This is my first iOS phone. I am very happy wi...  \n",
       "4   Really satisfied with the Product I received.....  \n",
       "5   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "6   So far it’s been an AMAZING experience coming ...  \n",
       "7   i11 is worthy to buy, too much happy with the ...  \n",
       "8   iphone 11 is a very good phone to buy only if ...  \n",
       "9   It’s a must buy who is looking for an upgrade ...  \n",
       "10  The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "11  Amazing phone with great cameras and better ba...  \n",
       "12  Previously I was using one plus 3t it was a gr...  \n",
       "13  This is my first iOS phone. I am very happy wi...  \n",
       "14  Really satisfied with the Product I received.....  \n",
       "15  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "16  So far it’s been an AMAZING experience coming ...  \n",
       "17  i11 is worthy to buy, too much happy with the ...  \n",
       "18  iphone 11 is a very good phone to buy only if ...  \n",
       "19  It’s a must buy who is looking for an upgrade ...  \n",
       "20  The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "21  Amazing phone with great cameras and better ba...  \n",
       "22  Previously I was using one plus 3t it was a gr...  \n",
       "23  This is my first iOS phone. I am very happy wi...  \n",
       "24  Really satisfied with the Product I received.....  \n",
       "25  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "26  So far it’s been an AMAZING experience coming ...  \n",
       "27  i11 is worthy to buy, too much happy with the ...  \n",
       "28  iphone 11 is a very good phone to buy only if ...  \n",
       "29  It’s a must buy who is looking for an upgrade ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products=pd.DataFrame({})\n",
    "products['Rating']=product_titles[:100]\n",
    "products['Summary']=product_summary[:100]\n",
    "products['Description']=product_review[:100]\n",
    "\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url6 ='https://www.flipkart.com/'  #set url here\n",
    "driver.get(url6)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')     #we can find it by id even we can find it with xpath\n",
    "search\n",
    "search.send_keys(\"sneakers\")                         #send on web browser we have to write Data Analyst\n",
    "search_btn=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')      #we can find it by id even we can find it with xpath\n",
    "\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sneakerssneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sneakerssneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sneakerssneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles=driver.find_elements_by_xpath(\"//div[@class='_2MImiq']/nav[@class='yFHi8N']/a\")\n",
    "Titles\n",
    "product_url=[]              #empty tag \n",
    "for i in Titles[:3]:\n",
    "     product_url.append(i.get_attribute('href')) \n",
    "product_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '4']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_titles=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_titles.append(i.text) \n",
    "product_titles[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robbie jones',\n",
       " 'Chevit',\n",
       " 'Numenzo',\n",
       " 'CALCADOS',\n",
       " 'Stefano Rads',\n",
       " 'KULP',\n",
       " 'World Wear Footwear',\n",
       " 'PEHANOSA',\n",
       " 'Labbin',\n",
       " 'Shoes Bank',\n",
       " 'Nilatin',\n",
       " 'Birde',\n",
       " 'Robbie jones',\n",
       " 'believe',\n",
       " 'ESSENCE',\n",
       " 'Numenzo',\n",
       " 'Chevit',\n",
       " 'bluemaker',\n",
       " 'SCATCHITE',\n",
       " 'BRUTON',\n",
       " 'World Wear Footwear',\n",
       " 'T-ROCK',\n",
       " 'Kraasa',\n",
       " 'HOTSTYLE',\n",
       " 'India hub',\n",
       " 'SPARX',\n",
       " 'bluemaker',\n",
       " 'Absolute comfort',\n",
       " 'Robbie jones',\n",
       " 'Robbie jones',\n",
       " 'D-SNEAKERZ',\n",
       " 'WRIZT',\n",
       " 'SPARX',\n",
       " 'Jokatoo',\n",
       " 'Robbie jones',\n",
       " 'World Wear Footwear',\n",
       " 'restinfoot',\n",
       " 'Arohi',\n",
       " 'HOTSTYLE',\n",
       " 'STRANGER BROTHERS',\n",
       " 'Robbie jones',\n",
       " 'Chevit',\n",
       " 'Numenzo',\n",
       " 'CALCADOS',\n",
       " 'Stefano Rads',\n",
       " 'KULP',\n",
       " 'World Wear Footwear',\n",
       " 'PEHANOSA',\n",
       " 'Labbin',\n",
       " 'Shoes Bank',\n",
       " 'Nilatin',\n",
       " 'Birde',\n",
       " 'Robbie jones',\n",
       " 'believe',\n",
       " 'ESSENCE',\n",
       " 'Numenzo',\n",
       " 'Chevit',\n",
       " 'bluemaker',\n",
       " 'SCATCHITE',\n",
       " 'BRUTON',\n",
       " 'World Wear Footwear',\n",
       " 'T-ROCK',\n",
       " 'Kraasa',\n",
       " 'HOTSTYLE',\n",
       " 'India hub',\n",
       " 'SPARX',\n",
       " 'bluemaker',\n",
       " 'Absolute comfort',\n",
       " 'Robbie jones',\n",
       " 'Robbie jones',\n",
       " 'D-SNEAKERZ',\n",
       " 'WRIZT',\n",
       " 'SPARX',\n",
       " 'Jokatoo',\n",
       " 'Robbie jones',\n",
       " 'World Wear Footwear',\n",
       " 'restinfoot',\n",
       " 'Arohi',\n",
       " 'HOTSTYLE',\n",
       " 'STRANGER BROTHERS',\n",
       " 'Robbie jones',\n",
       " 'Chevit',\n",
       " 'Numenzo',\n",
       " 'CALCADOS',\n",
       " 'Stefano Rads',\n",
       " 'KULP',\n",
       " 'World Wear Footwear',\n",
       " 'PEHANOSA',\n",
       " 'Labbin',\n",
       " 'Shoes Bank',\n",
       " 'Nilatin',\n",
       " 'Birde',\n",
       " 'Robbie jones',\n",
       " 'believe',\n",
       " 'ESSENCE',\n",
       " 'Numenzo',\n",
       " 'Chevit',\n",
       " 'bluemaker',\n",
       " 'SCATCHITE',\n",
       " 'BRUTON']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "product_titles=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_titles.append(i.text) \n",
    "product_titles[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Casual Sneakers Shoes For Men Sneakers For Men',\n",
       " 'Unique & Perfect Collection Combo Pack of 02 Shoes for ...',\n",
       " 'Sneakers For Men',\n",
       " 'heart beat Sneakers For Men',\n",
       " '5011-Latest Collection Stylish Casual Loafer Sneakers S...',\n",
       " 'Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " \"White Sneaker For Men's/Boy's Sneakers For Men\",\n",
       " 'Black Sneaker For Men Sneakers For Men',\n",
       " 'Combo Pack of 4 Casual Shoes Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Sneakers for men(black_6) Sneakers For Men',\n",
       " 'Casuals Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Speed Set of 5 Pairs Sneakers Outdoors Casuals for Men ...',\n",
       " 'Super Stylish & Trendy Combo Pack of 02 Pairs Sneakers ...',\n",
       " 'casual for men (blue 06) Sneakers For Men',\n",
       " 'Sneakers Sneakers For Men',\n",
       " 'Combo Pack Of 4 Casual Sneakers For Men',\n",
       " 'Super 445 Fashion Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Synthetic Leather Casual Partywear Wedding Sneakers Sho...',\n",
       " 'Series 7 Sneakers For Men',\n",
       " 'Fashionable casual sneakers shoes Sneakers For Men',\n",
       " 'casual for men (beige 06) Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Casual Sneakers Green Shoes For Men And Boys Sneakers F...',\n",
       " \"Casual , Partywear Sneakers Shoes For Men's And Boys Wh...\",\n",
       " 'SM-322 Sneakers For Men',\n",
       " 'Casual Sneakers Green Shoes For Men And Boys Sneakers F...',\n",
       " 'Latest Collection-1227 Stylish Casual Sports Sneakers F...',\n",
       " 'Casual shoes Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Casual Sneakers Shoes For Men Sneakers For Men',\n",
       " 'Unique & Perfect Collection Combo Pack of 02 Shoes for ...',\n",
       " 'Sneakers For Men',\n",
       " 'heart beat Sneakers For Men',\n",
       " '5011-Latest Collection Stylish Casual Loafer Sneakers S...',\n",
       " 'Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " \"White Sneaker For Men's/Boy's Sneakers For Men\",\n",
       " 'Black Sneaker For Men Sneakers For Men',\n",
       " 'Combo Pack of 4 Casual Shoes Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Sneakers for men(black_6) Sneakers For Men',\n",
       " 'Casuals Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Speed Set of 5 Pairs Sneakers Outdoors Casuals for Men ...',\n",
       " 'Super Stylish & Trendy Combo Pack of 02 Pairs Sneakers ...',\n",
       " 'casual for men (blue 06) Sneakers For Men',\n",
       " 'Sneakers Sneakers For Men',\n",
       " 'Combo Pack Of 4 Casual Sneakers For Men',\n",
       " 'Super 445 Fashion Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Synthetic Leather Casual Partywear Wedding Sneakers Sho...',\n",
       " 'Series 7 Sneakers For Men',\n",
       " 'Fashionable casual sneakers shoes Sneakers For Men',\n",
       " 'casual for men (beige 06) Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Casual Sneakers Green Shoes For Men And Boys Sneakers F...',\n",
       " \"Casual , Partywear Sneakers Shoes For Men's And Boys Wh...\",\n",
       " 'SM-322 Sneakers For Men',\n",
       " 'Casual Sneakers Green Shoes For Men And Boys Sneakers F...',\n",
       " 'Latest Collection-1227 Stylish Casual Sports Sneakers F...',\n",
       " 'Casual shoes Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Casual Sneakers Shoes For Men Sneakers For Men',\n",
       " 'Unique & Perfect Collection Combo Pack of 02 Shoes for ...',\n",
       " 'Sneakers For Men',\n",
       " 'heart beat Sneakers For Men',\n",
       " '5011-Latest Collection Stylish Casual Loafer Sneakers S...',\n",
       " 'Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " \"White Sneaker For Men's/Boy's Sneakers For Men\",\n",
       " 'Black Sneaker For Men Sneakers For Men',\n",
       " 'Combo Pack of 4 Casual Shoes Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Sneakers for men(black_6) Sneakers For Men',\n",
       " 'Casuals Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Speed Set of 5 Pairs Sneakers Outdoors Casuals for Men ...',\n",
       " 'Super Stylish & Trendy Combo Pack of 02 Pairs Sneakers ...',\n",
       " 'casual for men (blue 06) Sneakers For Men',\n",
       " 'Sneakers Sneakers For Men',\n",
       " 'Combo Pack Of 4 Casual Sneakers For Men',\n",
       " 'Super 445 Fashion Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Synthetic Leather Casual Partywear Wedding Sneakers Sho...',\n",
       " 'Series 7 Sneakers For Men',\n",
       " 'Fashionable casual sneakers shoes Sneakers For Men',\n",
       " 'casual for men (beige 06) Sneakers For Men',\n",
       " 'Sneakers For Men',\n",
       " 'Casual Sneakers Green Shoes For Men And Boys Sneakers F...',\n",
       " \"Casual , Partywear Sneakers Shoes For Men's And Boys Wh...\",\n",
       " 'SM-322 Sneakers For Men',\n",
       " 'Casual Sneakers Green Shoes For Men And Boys Sneakers F...',\n",
       " 'Latest Collection-1227 Stylish Casual Sports Sneakers F...',\n",
       " 'Casual shoes Sneakers For Men',\n",
       " 'Sneakers For Men']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_desc1=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_desc1.append(i.text) \n",
    "product_desc1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹379',\n",
       " '₹498',\n",
       " '₹378',\n",
       " '₹748',\n",
       " '₹242',\n",
       " '₹399',\n",
       " '₹240',\n",
       " '₹495',\n",
       " '₹499',\n",
       " '₹349',\n",
       " '₹449',\n",
       " '₹698',\n",
       " '₹474',\n",
       " '₹449',\n",
       " '₹399',\n",
       " '₹449',\n",
       " '₹756',\n",
       " '₹449',\n",
       " '₹398',\n",
       " '₹474',\n",
       " '₹240',\n",
       " '₹378',\n",
       " '₹499',\n",
       " '₹199',\n",
       " '₹449',\n",
       " '₹649',\n",
       " '₹449',\n",
       " '₹199',\n",
       " '₹499',\n",
       " '₹449',\n",
       " '₹365',\n",
       " '₹279',\n",
       " '₹799',\n",
       " '₹418',\n",
       " '₹499',\n",
       " '₹240',\n",
       " '₹379',\n",
       " '₹469',\n",
       " '₹283',\n",
       " '₹475',\n",
       " '₹379',\n",
       " '₹498',\n",
       " '₹378',\n",
       " '₹748',\n",
       " '₹242',\n",
       " '₹399',\n",
       " '₹240',\n",
       " '₹495',\n",
       " '₹499',\n",
       " '₹349',\n",
       " '₹449',\n",
       " '₹698',\n",
       " '₹474',\n",
       " '₹449',\n",
       " '₹399',\n",
       " '₹449',\n",
       " '₹756',\n",
       " '₹449',\n",
       " '₹398',\n",
       " '₹474',\n",
       " '₹240',\n",
       " '₹378',\n",
       " '₹499',\n",
       " '₹199',\n",
       " '₹449',\n",
       " '₹649',\n",
       " '₹449',\n",
       " '₹199',\n",
       " '₹499',\n",
       " '₹449',\n",
       " '₹365',\n",
       " '₹279',\n",
       " '₹799',\n",
       " '₹418',\n",
       " '₹499',\n",
       " '₹240',\n",
       " '₹379',\n",
       " '₹469',\n",
       " '₹283',\n",
       " '₹475',\n",
       " '₹379',\n",
       " '₹498',\n",
       " '₹378',\n",
       " '₹748',\n",
       " '₹242',\n",
       " '₹399',\n",
       " '₹240',\n",
       " '₹495',\n",
       " '₹499',\n",
       " '₹349',\n",
       " '₹449',\n",
       " '₹698',\n",
       " '₹474',\n",
       " '₹449',\n",
       " '₹399',\n",
       " '₹449',\n",
       " '₹756',\n",
       " '₹449',\n",
       " '₹398',\n",
       " '₹474']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_price=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_price.append(i.text) \n",
    "product_price[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['62% off',\n",
       " '66% off',\n",
       " '62% off',\n",
       " '62% off',\n",
       " '65% off',\n",
       " '60% off',\n",
       " '51% off',\n",
       " '50% off',\n",
       " '50% off',\n",
       " '65% off',\n",
       " '65% off',\n",
       " '65% off',\n",
       " '52% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '77% off',\n",
       " '69% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '88% off',\n",
       " '51% off',\n",
       " '62% off',\n",
       " '50% off',\n",
       " '60% off',\n",
       " '85% off',\n",
       " '7% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '50% off',\n",
       " '55% off',\n",
       " '44% off',\n",
       " '72% off',\n",
       " '20% off',\n",
       " '71% off',\n",
       " '50% off',\n",
       " '51% off',\n",
       " '62% off',\n",
       " '53% off',\n",
       " '43% off',\n",
       " '52% off',\n",
       " '62% off',\n",
       " '66% off',\n",
       " '62% off',\n",
       " '62% off',\n",
       " '65% off',\n",
       " '60% off',\n",
       " '51% off',\n",
       " '50% off',\n",
       " '50% off',\n",
       " '65% off',\n",
       " '65% off',\n",
       " '65% off',\n",
       " '52% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '77% off',\n",
       " '69% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '88% off',\n",
       " '51% off',\n",
       " '62% off',\n",
       " '50% off',\n",
       " '60% off',\n",
       " '85% off',\n",
       " '7% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '50% off',\n",
       " '55% off',\n",
       " '44% off',\n",
       " '72% off',\n",
       " '20% off',\n",
       " '71% off',\n",
       " '50% off',\n",
       " '51% off',\n",
       " '62% off',\n",
       " '53% off',\n",
       " '43% off',\n",
       " '52% off',\n",
       " '62% off',\n",
       " '66% off',\n",
       " '62% off',\n",
       " '62% off',\n",
       " '65% off',\n",
       " '60% off',\n",
       " '51% off',\n",
       " '50% off',\n",
       " '50% off',\n",
       " '65% off',\n",
       " '65% off',\n",
       " '65% off',\n",
       " '52% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '77% off',\n",
       " '69% off',\n",
       " '55% off',\n",
       " '60% off',\n",
       " '88% off']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_disc=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_disc.append(i.text) \n",
    "product_disc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹498</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefano Rads</td>\n",
       "      <td>₹242</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹756</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹474</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Price Discounts\n",
       "0   Robbie jones  ₹379   62% off\n",
       "1         Chevit  ₹498   66% off\n",
       "2        Numenzo  ₹378   62% off\n",
       "3       CALCADOS  ₹748   62% off\n",
       "4   Stefano Rads  ₹242   65% off\n",
       "..           ...   ...       ...\n",
       "95       Numenzo  ₹449   77% off\n",
       "96        Chevit  ₹756   69% off\n",
       "97     bluemaker  ₹449   55% off\n",
       "98     SCATCHITE  ₹398   60% off\n",
       "99        BRUTON  ₹474   88% off\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products=pd.DataFrame({})\n",
    "products['Name']=product_titles[:100]\n",
    "\n",
    "products['Price']=product_price[:100]\n",
    "products['Discounts']=product_disc[:100]\n",
    "#products['sed']=product_desc1[:100]       i don't get it\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-9: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "url9 ='https://www.myntra.com/shoes'  #set url here\n",
    "driver.get(url9)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Chk_price=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "Chk_price.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chk_black=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "Chk_black.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6649.0_13099.0_6649.0%20TO%2013099.0%2C6687.0_13125.0_6687.0%20TO%2013125.0',\n",
       " 'https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6649.0_13099.0_6649.0%20TO%2013099.0%2C6687.0_13125.0_6687.0%20TO%2013125.0',\n",
       " 'https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6649.0_13099.0_6649.0%20TO%2013099.0%2C6687.0_13125.0_6687.0%20TO%2013125.0&p=2']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles=driver.find_elements_by_xpath(\"//div[@class='results-showMoreContainer']/ul[@class='pagination-container']/li/a\")\n",
    "Titles\n",
    "product_url=[]              #empty tag \n",
    "for i in Titles[:3]:\n",
    "     product_url.append(i.get_attribute('href')) \n",
    "product_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nike',\n",
       " 'Lacoste',\n",
       " 'Saint G',\n",
       " 'Nike',\n",
       " 'RARE RABBIT',\n",
       " 'Nike',\n",
       " 'Geox',\n",
       " 'Nike',\n",
       " 'Geox',\n",
       " 'Bugatti',\n",
       " 'ALDO',\n",
       " 'Nike',\n",
       " 'DAVINCHI',\n",
       " 'DAVINCHI',\n",
       " 'DAVINCHI',\n",
       " 'Nike',\n",
       " 'Geox',\n",
       " 'Ruosh',\n",
       " 'Heel & Buckle London',\n",
       " 'Geox',\n",
       " 'Bugatti',\n",
       " 'Hush Puppies',\n",
       " 'Geox',\n",
       " 'Saint G',\n",
       " 'Cole Haan',\n",
       " 'Cole Haan',\n",
       " 'Geox',\n",
       " 'Florsheim',\n",
       " 'Cole Haan',\n",
       " 'Louis Philippe',\n",
       " 'VIONIC',\n",
       " 'ADIDAS',\n",
       " 'J.FONTINI',\n",
       " 'Hush Puppies',\n",
       " 'Hush Puppies',\n",
       " 'UNDER ARMOUR',\n",
       " 'KLEAT',\n",
       " 'J.FONTINI',\n",
       " 'Lacoste',\n",
       " 'Lacoste',\n",
       " 'ASICS',\n",
       " 'KLEAT',\n",
       " 'Ruosh',\n",
       " 'UNDER ARMOUR',\n",
       " 'Cole Haan',\n",
       " 'Nike',\n",
       " 'Cole Haan',\n",
       " 'Geox',\n",
       " 'Geox',\n",
       " 'ALDO',\n",
       " 'Nike',\n",
       " 'Lacoste',\n",
       " 'Saint G',\n",
       " 'Nike',\n",
       " 'RARE RABBIT',\n",
       " 'Nike',\n",
       " 'Geox',\n",
       " 'Nike',\n",
       " 'Geox',\n",
       " 'Bugatti',\n",
       " 'ALDO',\n",
       " 'Nike',\n",
       " 'DAVINCHI',\n",
       " 'DAVINCHI',\n",
       " 'DAVINCHI',\n",
       " 'Nike',\n",
       " 'Geox',\n",
       " 'Ruosh',\n",
       " 'Heel & Buckle London',\n",
       " 'Geox',\n",
       " 'Bugatti',\n",
       " 'Hush Puppies',\n",
       " 'Geox',\n",
       " 'Saint G',\n",
       " 'Cole Haan',\n",
       " 'Cole Haan',\n",
       " 'Geox',\n",
       " 'Florsheim',\n",
       " 'Cole Haan',\n",
       " 'Louis Philippe',\n",
       " 'VIONIC',\n",
       " 'ADIDAS',\n",
       " 'J.FONTINI',\n",
       " 'Hush Puppies',\n",
       " 'Hush Puppies',\n",
       " 'UNDER ARMOUR',\n",
       " 'KLEAT',\n",
       " 'J.FONTINI',\n",
       " 'Lacoste',\n",
       " 'Lacoste',\n",
       " 'ASICS',\n",
       " 'KLEAT',\n",
       " 'Ruosh',\n",
       " 'UNDER ARMOUR',\n",
       " 'Cole Haan',\n",
       " 'Nike',\n",
       " 'Cole Haan',\n",
       " 'Geox',\n",
       " 'Geox',\n",
       " 'ALDO']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_titles=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_titles.append(i.text) \n",
    "product_titles[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_titles[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Women AIR MAX VIVA Sneakers',\n",
       " 'Men Colourblocked Sneakers',\n",
       " 'Men Leather Chelsea Boots',\n",
       " 'Men AIR ZOOM PEGASUS 38 Run',\n",
       " 'Men Perforations Leather Brogues',\n",
       " 'Men Zoom Winflo 8 Running',\n",
       " 'Men Leather Semiformal Driving',\n",
       " 'Men AIR ZOOM PEGASUS 38 Run',\n",
       " 'Men Leather Formal Derbys',\n",
       " 'Men Solid Leather Formal Monk Shoes',\n",
       " 'Women Sandals',\n",
       " 'Men REACT MILER 2 Running',\n",
       " 'Men Formal Leather Slip-Ons',\n",
       " 'Ustraa black',\n",
       " 'Men Textured Formal Leather Loafers',\n",
       " 'Men REACT MILER 2 Running',\n",
       " 'Men Leather Formal Slip-Ons',\n",
       " 'Men Formal Leather Brogues',\n",
       " 'Women Peep Toe Heels',\n",
       " 'Men Leather Driving Shoes',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Men Leather Formal Derbys',\n",
       " 'Men Leather Formal Derbys',\n",
       " 'Women Leather Heeled Boots',\n",
       " 'Men Wingtip Oxford Sneakers',\n",
       " 'Men GENERATION ZEROGRAND STITCHLITE',\n",
       " 'Men Leather Slip-On Sneakers',\n",
       " 'Men Solid Leather Formal Loafers',\n",
       " 'Leather Sneakers',\n",
       " 'Men Leather Formal Slip-Ons',\n",
       " 'Men Textured Sneakers',\n",
       " 'Women Edge Lux 4 Running',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Men Textured Oxfords',\n",
       " 'Men Woven Design Sneakers',\n",
       " 'HOVR Infinite 2 Running Shoes',\n",
       " 'Men Woven Design Loafers',\n",
       " 'Men Solid Loafers',\n",
       " 'Men Woven Design Sneakers',\n",
       " 'Woven Design Casual Sneakers',\n",
       " 'Men Running Shoes',\n",
       " 'Men Woven Design Sneakers',\n",
       " 'Men Leather Formal Brogues',\n",
       " 'Women HOVR Infinite 2 Running',\n",
       " 'Women Open Toe Flats',\n",
       " 'Men AIR MAX INFINITY Sneakers',\n",
       " 'Women Sneakers',\n",
       " 'Women Solid Leather Loafers',\n",
       " 'Men Leather Formal Monks',\n",
       " 'Women Solid Leather Pumps',\n",
       " 'Women AIR MAX VIVA Sneakers',\n",
       " 'Men Colourblocked Sneakers',\n",
       " 'Men Leather Chelsea Boots',\n",
       " 'Men AIR ZOOM PEGASUS 38 Run',\n",
       " 'Men Perforations Leather Brogues',\n",
       " 'Men Zoom Winflo 8 Running',\n",
       " 'Men Leather Semiformal Driving',\n",
       " 'Men AIR ZOOM PEGASUS 38 Run',\n",
       " 'Men Leather Formal Derbys',\n",
       " 'Men Solid Leather Formal Monk Shoes',\n",
       " 'Women Sandals',\n",
       " 'Men REACT MILER 2 Running',\n",
       " 'Men Formal Leather Slip-Ons',\n",
       " 'Ustraa black',\n",
       " 'Men Textured Formal Leather Loafers',\n",
       " 'Men REACT MILER 2 Running',\n",
       " 'Men Leather Formal Slip-Ons',\n",
       " 'Men Formal Leather Brogues',\n",
       " 'Women Peep Toe Heels',\n",
       " 'Men Leather Driving Shoes',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Men Leather Formal Derbys',\n",
       " 'Men Leather Formal Derbys',\n",
       " 'Women Leather Heeled Boots',\n",
       " 'Men Wingtip Oxford Sneakers',\n",
       " 'Men GENERATION ZEROGRAND STITCHLITE',\n",
       " 'Men Leather Slip-On Sneakers',\n",
       " 'Men Solid Leather Formal Loafers',\n",
       " 'Leather Sneakers',\n",
       " 'Men Leather Formal Slip-Ons',\n",
       " 'Men Textured Sneakers',\n",
       " 'Women Edge Lux 4 Running',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Men Textured Oxfords',\n",
       " 'Men Woven Design Sneakers',\n",
       " 'HOVR Infinite 2 Running Shoes',\n",
       " 'Men Woven Design Loafers',\n",
       " 'Men Solid Loafers',\n",
       " 'Men Woven Design Sneakers',\n",
       " 'Woven Design Casual Sneakers',\n",
       " 'Men Running Shoes',\n",
       " 'Men Woven Design Sneakers',\n",
       " 'Men Leather Formal Brogues',\n",
       " 'Women HOVR Infinite 2 Running',\n",
       " 'Women Open Toe Flats',\n",
       " 'Men AIR MAX INFINITY Sneakers',\n",
       " 'Women Sneakers',\n",
       " 'Women Solid Leather Loafers',\n",
       " 'Men Leather Formal Monks',\n",
       " 'Women Solid Leather Pumps']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_desc_M=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//H4[@class='product-product']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_desc_M.append(i.text) \n",
    "product_desc_M[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_desc_M[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 9371Rs. 12495',\n",
       " 'Rs. 8650',\n",
       " 'Rs. 11305Rs. 11900',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8295',\n",
       " 'Rs. 10490',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 7349Rs. 10499',\n",
       " 'Rs. 8499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 11495',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 11495',\n",
       " 'Rs. 7495Rs. 14990',\n",
       " 'Rs. 7490',\n",
       " 'Rs. 7192Rs. 8990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 10499',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6995Rs. 13990',\n",
       " 'Rs. 6675Rs. 8900',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 9490',\n",
       " 'Rs. 6995',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7039Rs. 10999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7690',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 8500',\n",
       " 'Rs. 7052Rs. 10850',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 8295',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999Rs. 15999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9371Rs. 12495',\n",
       " 'Rs. 8650',\n",
       " 'Rs. 11305Rs. 11900',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8295',\n",
       " 'Rs. 10490',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 7349Rs. 10499',\n",
       " 'Rs. 8499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 11495',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 11495',\n",
       " 'Rs. 7495Rs. 14990',\n",
       " 'Rs. 7490',\n",
       " 'Rs. 7192Rs. 8990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 10499',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6995Rs. 13990',\n",
       " 'Rs. 6675Rs. 8900',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 9490',\n",
       " 'Rs. 6995',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7039Rs. 10999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7690',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 8500',\n",
       " 'Rs. 7052Rs. 10850',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 6990',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 8295',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999Rs. 15999',\n",
       " 'Rs. 9999']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_price_M=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/div[@class='product-price']/span[1]\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_price_M.append(i.text) \n",
    "product_price_M[:100]\n",
    "#Error: i got original value after discounts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_price_M[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VIVA Sneakers</td>\n",
       "      <td>Rs. 9371Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lacoste</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "      <td>Rs. 8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Men Leather Chelsea Boots</td>\n",
       "      <td>Rs. 11305Rs. 11900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM PEGASUS 38 Run</td>\n",
       "      <td>Rs. 9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Men Perforations Leather Brogues</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX INFINITY Sneakers</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Leather Loafers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Monks</td>\n",
       "      <td>Rs. 7999Rs. 15999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Solid Leather Pumps</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name                       description               Price\n",
       "0          Nike       Women AIR MAX VIVA Sneakers   Rs. 9371Rs. 12495\n",
       "1       Lacoste        Men Colourblocked Sneakers            Rs. 8650\n",
       "2       Saint G         Men Leather Chelsea Boots  Rs. 11305Rs. 11900\n",
       "3          Nike       Men AIR ZOOM PEGASUS 38 Run            Rs. 9995\n",
       "4   RARE RABBIT  Men Perforations Leather Brogues            Rs. 6999\n",
       "..          ...                               ...                 ...\n",
       "95         Nike     Men AIR MAX INFINITY Sneakers            Rs. 8295\n",
       "96    Cole Haan                    Women Sneakers           Rs. 12999\n",
       "97         Geox       Women Solid Leather Loafers            Rs. 7999\n",
       "98         Geox          Men Leather Formal Monks   Rs. 7999Rs. 15999\n",
       "99         ALDO         Women Solid Leather Pumps            Rs. 9999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products=pd.DataFrame({})\n",
    "products['Name']=product_titles[:100]\n",
    "products['description']=product_desc_M[:100]\n",
    "products['Price']=product_price_M[:100]\n",
    "\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10: Go to webpage https://www.amazon.in/   Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "url10 ='https://www.amazon.in/'  #set url here\n",
    "driver.get(url10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath('//*[@id=\"twotabsearchtextbox\"]')     #we can find it by id even we can find it with xpath\n",
    "search\n",
    "search.send_keys(\"Laptop\")                         #send on web browser we have to write Data Analyst\n",
    "search_btn=driver.find_element_by_xpath('//*[@id=\"nav-search-submit-button\"]')      #we can find it by id even we can find it with xpath\n",
    "\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chk_price=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div')\n",
    "Chk_price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chk_price=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/div')\n",
    "Chk_price.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1625946632&rnid=12598141031&ref=sr_pg_1',\n",
       " 'https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&page=2&qid=1625946632&rnid=12598141031&ref=sr_pg_2',\n",
       " 'https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&page=3&qid=1625946632&rnid=12598141031&ref=sr_pg_3',\n",
       " 'https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&page=2&qid=1625946632&rnid=12598141031&ref=sr_pg_1']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles=driver.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none a-padding-base']/div[@class='a-text-center']/ul[@class='a-pagination']/li/a\")\n",
    "product_url=[]              #empty tag \n",
    "for i in Titles[:4]:\n",
    "     product_url.append(i.get_attribute('href')) \n",
    "product_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " 'Lenovo Legion 7 10th Gen Intel Core i7 15.6 inch Full HD Gaming Laptop (16GB/1TB SSD/Windows 10/MS Office 2019/144 Hz/NVIDIA RTX 2080 8GB GDDR6 Graphics/Slate Grey/2.25Kg), 81YU002AIN',\n",
       " 'HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AF+Webcam',\n",
       " 'ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Core i7-10870H 10th Gen, GTX 1650 Ti GDDR6 4GB Graphics, Gaming Laptop (16GB RAM/1TB HDD + 256GB SSD/Windows 10/Fortress Gray/2.3 Kg), FX566LI-HN133T',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'HP Pavilion x360 (2021) 14\" (35.56cms) FHD Touchscreen Laptop, 11th Gen Core i7, 8 GB RAM, 512GB SSD, 2-in-1 Convertible, Windows 10, MS Office, Finger Print Reader (14-dw1040TU)',\n",
       " 'Dell Inspiron 15 Gaming 7567 15.6-inch Laptop (7th Gen Core i7-7700HQ/8GB/1TB/Windows 10 with Microsoft Office Home & Student 2016/4GB Graphics)',\n",
       " 'Dell 14 (2021) i7-1165G7 2in1 Touch Screen Laptop, 16Gb RAM, 512Gb SSD, 14” (35.56 cms) FHD Display, Win 10 + MSO, Backlit KB + FPR + Active Pen, Silver Metal Color (Inspiron 5410, D560469WIN9S)',\n",
       " 'HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (11th Gen Intel i7-1165G7/8GB/512GB SSD/Windows 10/MS Office 2019/Alexa Built-in/Pale Gold/1.47 kg), 14s-dr2007TU',\n",
       " 'ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 144Hz/3ms Gaming Laptop (8th Gen Intel Core i9-8950HK/64GB/2TB SSHD + 1.5TB NVMe SSD/Windows 10/GTX 1080 8GB Graphics/4.70 Kg), Aluminum',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (16GB RAM /1TB SSD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'ASUS VivoBook S S14 Intel Core i7-1165G7 11th Gen 14-inch FHD Thin and Light Laptop (8GB RAM/512GB SSD + 32GB Optane Memory/Windows 10/Office 2019/Iris X Graphics ;Dreamy White;1.4 Kg), S433EA-AM702TS',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (8GB RAM/1TB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Dell Alienware m15(R3) 15.6-inch FHD Gaming Laptop (10th Gen Core i7-10750H/16GB/512GB SSD/Windows 10 Home & MS Office/6GB NVIDIA GTX 1660 Ti Graphics), Lunar Light',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm) FHD IPS-Level 144Hz Panel Laptop (8GB/512GB NVMe SSD/Windows 10 Home/Nvidia GTX1650 4GB GDDR6/Black/2.2Kg), 10SCXR-654IN',\n",
       " 'MSI GF63 Thin 10SCSR-019IN Intel Core i7-10750H 10th Gen 15.6-inch 120Hz Laptop(8GB/512GB NVMe SSD /Windows 10 Home/Nvidia GeForce GTX 1650Ti Max-Q 4GB/Black/1.8Kg ) 9S7-16R412-019',\n",
       " 'Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14-inch FHD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Win 10/Office 2019/Lenovo Digital Pen Stylus/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN',\n",
       " 'Asus ROG Zephyrus S Ultra Slim Gaming Laptop, 15.6\" 144Hz IPS Type FHD, GeForce RTX 2070, Intel Core i7-8750H, 16GB DDR4, 512GB PCIe NVMe SSD, Aura Sync RGB, Windows 10, GX531GW-AS76',\n",
       " 'Lenovo Legion Y540 Intel Core i7 9th Gen 15.6” FHD Gaming (8GB/256SSD + 1TBHDD/Win10/NVIDIA GeForce GTX 1650 4GB/Raven Black/2.3kg), 81SY00U7IN',\n",
       " '(Renewed) Dell Intel Core i7 7th Gen12.5 Inch(31.75 cms) (1920 x 1080)FHD TOUCHSCREEN Laptop (8GB RAM/256GB SSD/Windows 10 Pro/MS Office/Intel Integrated HD Graphics /1.18Kg,Black) Latitude E7280',\n",
       " '(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15-Inch (38.1 cms) 1366x768 Laptop (8 GB/500 GB HDD/Windows/MS Office Pro 2019 /AMD/Black/2.47 Kg), Latitude E5570',\n",
       " '(Renewed) Lenovo Yoga 900 Laptop 80UE00BLIH (Core i7 (6th Gen)/512 GB/8 GB/33.78 cm (13.3)/Windows 10) (Champagne Gold)',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (4GB RAM/320GB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 4GB RAM, 256GB SSD, Windows 10), ZED AIR CX7',\n",
       " 'Dell Inspiron 5406 14\" FHD Touch Display 2in1 Laptop (11th Gen i7-1165G7 / 8Gb / 512Gb SSD / Integrated Graphics / Win 10 + MSO / Titan Grey Color / FPR/ Active Pen) D560414WIN9S',\n",
       " 'NEXSTGO Primus NX201 NP15N1IN008P 15.6-inch Laptop (Core i7-8550U/8GB/256GBSSD/Windows 10 Pro/Full HD + IR/Finger Print/Integrated Graphics/Thin & Light/1.88KG), Dark Gray',\n",
       " 'Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120hz FHD Display Laptop (10th Gen i7-10750H / 8 GB / 512 SSD / GTX 1650 4GB / 1Yr Premium Warranty/ Win 10 + MS Office H&S 2019) D560250WIN9BE',\n",
       " 'ASUS ROG Zephyrus S15 (2020), 15.6\" FHD 300Hz/3ms, Intel Core i7-10875H 10th Gen, RTX 2080 Super Max-Q 8GB Graphics, Gaming Laptop (32GB/1TB RAID 0 SSD/Windows 10/Black/1.9 Kg), GX502LXS-HF081T',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " 'Lenovo Legion 7 10th Gen Intel Core i7 15.6 inch Full HD Gaming Laptop (16GB/1TB SSD/Windows 10/MS Office 2019/144 Hz/NVIDIA RTX 2080 8GB GDDR6 Graphics/Slate Grey/2.25Kg), 81YU002AIN',\n",
       " 'HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AF+Webcam',\n",
       " 'ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Core i7-10870H 10th Gen, GTX 1650 Ti GDDR6 4GB Graphics, Gaming Laptop (16GB RAM/1TB HDD + 256GB SSD/Windows 10/Fortress Gray/2.3 Kg), FX566LI-HN133T',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'HP Pavilion x360 (2021) 14\" (35.56cms) FHD Touchscreen Laptop, 11th Gen Core i7, 8 GB RAM, 512GB SSD, 2-in-1 Convertible, Windows 10, MS Office, Finger Print Reader (14-dw1040TU)',\n",
       " 'Dell Inspiron 15 Gaming 7567 15.6-inch Laptop (7th Gen Core i7-7700HQ/8GB/1TB/Windows 10 with Microsoft Office Home & Student 2016/4GB Graphics)',\n",
       " 'Dell 14 (2021) i7-1165G7 2in1 Touch Screen Laptop, 16Gb RAM, 512Gb SSD, 14” (35.56 cms) FHD Display, Win 10 + MSO, Backlit KB + FPR + Active Pen, Silver Metal Color (Inspiron 5410, D560469WIN9S)',\n",
       " 'HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (11th Gen Intel i7-1165G7/8GB/512GB SSD/Windows 10/MS Office 2019/Alexa Built-in/Pale Gold/1.47 kg), 14s-dr2007TU',\n",
       " 'ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 144Hz/3ms Gaming Laptop (8th Gen Intel Core i9-8950HK/64GB/2TB SSHD + 1.5TB NVMe SSD/Windows 10/GTX 1080 8GB Graphics/4.70 Kg), Aluminum',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (16GB RAM /1TB SSD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'ASUS VivoBook S S14 Intel Core i7-1165G7 11th Gen 14-inch FHD Thin and Light Laptop (8GB RAM/512GB SSD + 32GB Optane Memory/Windows 10/Office 2019/Iris X Graphics ;Dreamy White;1.4 Kg), S433EA-AM702TS',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (8GB RAM/1TB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Dell Alienware m15(R3) 15.6-inch FHD Gaming Laptop (10th Gen Core i7-10750H/16GB/512GB SSD/Windows 10 Home & MS Office/6GB NVIDIA GTX 1660 Ti Graphics), Lunar Light',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm) FHD IPS-Level 144Hz Panel Laptop (8GB/512GB NVMe SSD/Windows 10 Home/Nvidia GTX1650 4GB GDDR6/Black/2.2Kg), 10SCXR-654IN',\n",
       " 'MSI GF63 Thin 10SCSR-019IN Intel Core i7-10750H 10th Gen 15.6-inch 120Hz Laptop(8GB/512GB NVMe SSD /Windows 10 Home/Nvidia GeForce GTX 1650Ti Max-Q 4GB/Black/1.8Kg ) 9S7-16R412-019',\n",
       " 'Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14-inch FHD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Win 10/Office 2019/Lenovo Digital Pen Stylus/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN',\n",
       " 'Asus ROG Zephyrus S Ultra Slim Gaming Laptop, 15.6\" 144Hz IPS Type FHD, GeForce RTX 2070, Intel Core i7-8750H, 16GB DDR4, 512GB PCIe NVMe SSD, Aura Sync RGB, Windows 10, GX531GW-AS76',\n",
       " 'Lenovo Legion Y540 Intel Core i7 9th Gen 15.6” FHD Gaming (8GB/256SSD + 1TBHDD/Win10/NVIDIA GeForce GTX 1650 4GB/Raven Black/2.3kg), 81SY00U7IN',\n",
       " '(Renewed) Dell Intel Core i7 7th Gen12.5 Inch(31.75 cms) (1920 x 1080)FHD TOUCHSCREEN Laptop (8GB RAM/256GB SSD/Windows 10 Pro/MS Office/Intel Integrated HD Graphics /1.18Kg,Black) Latitude E7280',\n",
       " '(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15-Inch (38.1 cms) 1366x768 Laptop (8 GB/500 GB HDD/Windows/MS Office Pro 2019 /AMD/Black/2.47 Kg), Latitude E5570',\n",
       " '(Renewed) Lenovo Yoga 900 Laptop 80UE00BLIH (Core i7 (6th Gen)/512 GB/8 GB/33.78 cm (13.3)/Windows 10) (Champagne Gold)',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (4GB RAM/320GB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 4GB RAM, 256GB SSD, Windows 10), ZED AIR CX7',\n",
       " 'Dell Inspiron 5406 14\" FHD Touch Display 2in1 Laptop (11th Gen i7-1165G7 / 8Gb / 512Gb SSD / Integrated Graphics / Win 10 + MSO / Titan Grey Color / FPR/ Active Pen) D560414WIN9S',\n",
       " 'NEXSTGO Primus NX201 NP15N1IN008P 15.6-inch Laptop (Core i7-8550U/8GB/256GBSSD/Windows 10 Pro/Full HD + IR/Finger Print/Integrated Graphics/Thin & Light/1.88KG), Dark Gray',\n",
       " 'Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120hz FHD Display Laptop (10th Gen i7-10750H / 8 GB / 512 SSD / GTX 1650 4GB / 1Yr Premium Warranty/ Win 10 + MS Office H&S 2019) D560250WIN9BE',\n",
       " 'ASUS ROG Zephyrus S15 (2020), 15.6\" FHD 300Hz/3ms, Intel Core i7-10875H 10th Gen, RTX 2080 Super Max-Q 8GB Graphics, Gaming Laptop (32GB/1TB RAID 0 SSD/Windows 10/Black/1.9 Kg), GX502LXS-HF081T',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " 'Lenovo Legion 7 10th Gen Intel Core i7 15.6 inch Full HD Gaming Laptop (16GB/1TB SSD/Windows 10/MS Office 2019/144 Hz/NVIDIA RTX 2080 8GB GDDR6 Graphics/Slate Grey/2.25Kg), 81YU002AIN',\n",
       " 'HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AF+Webcam',\n",
       " 'ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Core i7-10870H 10th Gen, GTX 1650 Ti GDDR6 4GB Graphics, Gaming Laptop (16GB RAM/1TB HDD + 256GB SSD/Windows 10/Fortress Gray/2.3 Kg), FX566LI-HN133T',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'HP Pavilion x360 (2021) 14\" (35.56cms) FHD Touchscreen Laptop, 11th Gen Core i7, 8 GB RAM, 512GB SSD, 2-in-1 Convertible, Windows 10, MS Office, Finger Print Reader (14-dw1040TU)',\n",
       " 'Dell Inspiron 15 Gaming 7567 15.6-inch Laptop (7th Gen Core i7-7700HQ/8GB/1TB/Windows 10 with Microsoft Office Home & Student 2016/4GB Graphics)',\n",
       " 'Dell 14 (2021) i7-1165G7 2in1 Touch Screen Laptop, 16Gb RAM, 512Gb SSD, 14” (35.56 cms) FHD Display, Win 10 + MSO, Backlit KB + FPR + Active Pen, Silver Metal Color (Inspiron 5410, D560469WIN9S)',\n",
       " 'HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (11th Gen Intel i7-1165G7/8GB/512GB SSD/Windows 10/MS Office 2019/Alexa Built-in/Pale Gold/1.47 kg), 14s-dr2007TU',\n",
       " 'ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 144Hz/3ms Gaming Laptop (8th Gen Intel Core i9-8950HK/64GB/2TB SSHD + 1.5TB NVMe SSD/Windows 10/GTX 1080 8GB Graphics/4.70 Kg), Aluminum',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (16GB RAM /1TB SSD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'ASUS VivoBook S S14 Intel Core i7-1165G7 11th Gen 14-inch FHD Thin and Light Laptop (8GB RAM/512GB SSD + 32GB Optane Memory/Windows 10/Office 2019/Iris X Graphics ;Dreamy White;1.4 Kg), S433EA-AM702TS',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (8GB RAM/1TB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Dell Alienware m15(R3) 15.6-inch FHD Gaming Laptop (10th Gen Core i7-10750H/16GB/512GB SSD/Windows 10 Home & MS Office/6GB NVIDIA GTX 1660 Ti Graphics), Lunar Light',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm) FHD IPS-Level 144Hz Panel Laptop (8GB/512GB NVMe SSD/Windows 10 Home/Nvidia GTX1650 4GB GDDR6/Black/2.2Kg), 10SCXR-654IN',\n",
       " 'MSI GF63 Thin 10SCSR-019IN Intel Core i7-10750H 10th Gen 15.6-inch 120Hz Laptop(8GB/512GB NVMe SSD /Windows 10 Home/Nvidia GeForce GTX 1650Ti Max-Q 4GB/Black/1.8Kg ) 9S7-16R412-019',\n",
       " 'Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14-inch FHD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Win 10/Office 2019/Lenovo Digital Pen Stylus/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN',\n",
       " 'Asus ROG Zephyrus S Ultra Slim Gaming Laptop, 15.6\" 144Hz IPS Type FHD, GeForce RTX 2070, Intel Core i7-8750H, 16GB DDR4, 512GB PCIe NVMe SSD, Aura Sync RGB, Windows 10, GX531GW-AS76',\n",
       " 'Lenovo Legion Y540 Intel Core i7 9th Gen 15.6” FHD Gaming (8GB/256SSD + 1TBHDD/Win10/NVIDIA GeForce GTX 1650 4GB/Raven Black/2.3kg), 81SY00U7IN',\n",
       " '(Renewed) Dell Intel Core i7 7th Gen12.5 Inch(31.75 cms) (1920 x 1080)FHD TOUCHSCREEN Laptop (8GB RAM/256GB SSD/Windows 10 Pro/MS Office/Intel Integrated HD Graphics /1.18Kg,Black) Latitude E7280',\n",
       " '(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15-Inch (38.1 cms) 1366x768 Laptop (8 GB/500 GB HDD/Windows/MS Office Pro 2019 /AMD/Black/2.47 Kg), Latitude E5570',\n",
       " '(Renewed) Lenovo Yoga 900 Laptop 80UE00BLIH (Core i7 (6th Gen)/512 GB/8 GB/33.78 cm (13.3)/Windows 10) (Champagne Gold)',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (4GB RAM/320GB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 4GB RAM, 256GB SSD, Windows 10), ZED AIR CX7',\n",
       " 'Dell Inspiron 5406 14\" FHD Touch Display 2in1 Laptop (11th Gen i7-1165G7 / 8Gb / 512Gb SSD / Integrated Graphics / Win 10 + MSO / Titan Grey Color / FPR/ Active Pen) D560414WIN9S',\n",
       " 'NEXSTGO Primus NX201 NP15N1IN008P 15.6-inch Laptop (Core i7-8550U/8GB/256GBSSD/Windows 10 Pro/Full HD + IR/Finger Print/Integrated Graphics/Thin & Light/1.88KG), Dark Gray',\n",
       " 'Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120hz FHD Display Laptop (10th Gen i7-10750H / 8 GB / 512 SSD / GTX 1650 4GB / 1Yr Premium Warranty/ Win 10 + MS Office H&S 2019) D560250WIN9BE',\n",
       " 'ASUS ROG Zephyrus S15 (2020), 15.6\" FHD 300Hz/3ms, Intel Core i7-10875H 10th Gen, RTX 2080 Super Max-Q 8GB Graphics, Gaming Laptop (32GB/1TB RAID 0 SSD/Windows 10/Black/1.9 Kg), GX502LXS-HF081T',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " 'Lenovo Legion 7 10th Gen Intel Core i7 15.6 inch Full HD Gaming Laptop (16GB/1TB SSD/Windows 10/MS Office 2019/144 Hz/NVIDIA RTX 2080 8GB GDDR6 Graphics/Slate Grey/2.25Kg), 81YU002AIN',\n",
       " 'HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AF+Webcam',\n",
       " 'ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Core i7-10870H 10th Gen, GTX 1650 Ti GDDR6 4GB Graphics, Gaming Laptop (16GB RAM/1TB HDD + 256GB SSD/Windows 10/Fortress Gray/2.3 Kg), FX566LI-HN133T',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'HP Pavilion x360 (2021) 14\" (35.56cms) FHD Touchscreen Laptop, 11th Gen Core i7, 8 GB RAM, 512GB SSD, 2-in-1 Convertible, Windows 10, MS Office, Finger Print Reader (14-dw1040TU)',\n",
       " 'Dell Inspiron 15 Gaming 7567 15.6-inch Laptop (7th Gen Core i7-7700HQ/8GB/1TB/Windows 10 with Microsoft Office Home & Student 2016/4GB Graphics)',\n",
       " 'Dell 14 (2021) i7-1165G7 2in1 Touch Screen Laptop, 16Gb RAM, 512Gb SSD, 14” (35.56 cms) FHD Display, Win 10 + MSO, Backlit KB + FPR + Active Pen, Silver Metal Color (Inspiron 5410, D560469WIN9S)',\n",
       " 'HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (11th Gen Intel i7-1165G7/8GB/512GB SSD/Windows 10/MS Office 2019/Alexa Built-in/Pale Gold/1.47 kg), 14s-dr2007TU']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_titles=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_titles.append(i.text) \n",
    "product_titles[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_titles[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹54,999',\n",
       " '₹2,00,000',\n",
       " '₹84,990',\n",
       " '₹59,999',\n",
       " '₹81,990',\n",
       " '₹96,555',\n",
       " '₹76,990',\n",
       " '₹78,990',\n",
       " '₹91,450',\n",
       " '₹88,990',\n",
       " '₹5,39,322',\n",
       " '₹49,999',\n",
       " '₹76,990',\n",
       " '₹43,999',\n",
       " '₹1,74,990',\n",
       " '₹96,555',\n",
       " '₹81,770',\n",
       " '₹84,990',\n",
       " '₹83,990',\n",
       " '₹69,990',\n",
       " '₹54,999',\n",
       " '₹61,799',\n",
       " '₹55,990',\n",
       " '₹39,999',\n",
       " '₹40,932',\n",
       " '₹56,155',\n",
       " '₹86,390',\n",
       " '₹1,98,960',\n",
       " '₹54,999',\n",
       " '₹2,00,000',\n",
       " '₹84,990',\n",
       " '₹59,999',\n",
       " '₹81,990',\n",
       " '₹96,555',\n",
       " '₹76,990',\n",
       " '₹78,990',\n",
       " '₹91,450',\n",
       " '₹88,990',\n",
       " '₹5,39,322',\n",
       " '₹49,999',\n",
       " '₹76,990',\n",
       " '₹43,999',\n",
       " '₹1,74,990',\n",
       " '₹96,555',\n",
       " '₹81,770',\n",
       " '₹84,990',\n",
       " '₹83,990',\n",
       " '₹69,990',\n",
       " '₹54,999',\n",
       " '₹61,799',\n",
       " '₹55,990',\n",
       " '₹39,999',\n",
       " '₹40,932',\n",
       " '₹56,155',\n",
       " '₹86,390',\n",
       " '₹1,98,960',\n",
       " '₹54,999',\n",
       " '₹2,00,000',\n",
       " '₹84,990',\n",
       " '₹59,999',\n",
       " '₹81,990',\n",
       " '₹96,555',\n",
       " '₹76,990',\n",
       " '₹78,990',\n",
       " '₹91,450',\n",
       " '₹88,990',\n",
       " '₹5,39,322',\n",
       " '₹49,999',\n",
       " '₹76,990',\n",
       " '₹43,999',\n",
       " '₹1,74,990',\n",
       " '₹96,555',\n",
       " '₹81,770',\n",
       " '₹84,990',\n",
       " '₹83,990',\n",
       " '₹69,990',\n",
       " '₹54,999',\n",
       " '₹61,799',\n",
       " '₹55,990',\n",
       " '₹39,999',\n",
       " '₹40,932',\n",
       " '₹56,155',\n",
       " '₹86,390',\n",
       " '₹1,98,960',\n",
       " '₹54,999',\n",
       " '₹2,00,000',\n",
       " '₹84,990',\n",
       " '₹59,999',\n",
       " '₹81,990',\n",
       " '₹96,555',\n",
       " '₹76,990',\n",
       " '₹78,990',\n",
       " '₹91,450',\n",
       " '₹88,990',\n",
       " '₹5,39,322',\n",
       " '₹49,999',\n",
       " '₹76,990',\n",
       " '₹43,999',\n",
       " '₹1,74,990',\n",
       " '₹96,555']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_desc_A=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//span[@class='a-price']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_desc_A.append(i.text) \n",
    "product_desc_A[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_desc_A[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_desc_A=[]\n",
    "\n",
    "for i in product_url:   \n",
    "    Titles=driver.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none a-spacing-top-micro']/div/i[@class='a-icon a-icon-star-small a-star-small-4-5 aok-align-bottom']/span[@class='a-icon-alt']\")\n",
    "    Titles\n",
    "    for i in Titles[:100]:\n",
    "        product_desc_A.append(i.text) \n",
    "product_desc_A[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>Women AIR MAX VIVA Sneakers</td>\n",
       "      <td>Rs. 9371Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "      <td>Rs. 8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>Men Leather Chelsea Boots</td>\n",
       "      <td>Rs. 11305Rs. 11900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>Men AIR ZOOM PEGASUS 38 Run</td>\n",
       "      <td>Rs. 9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...</td>\n",
       "      <td>Men Perforations Leather Brogues</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>Men AIR MAX INFINITY Sneakers</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Dell Inspiron 15 Gaming 7567 15.6-inch Laptop ...</td>\n",
       "      <td>Women Solid Leather Loafers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>Men Leather Formal Monks</td>\n",
       "      <td>Rs. 7999Rs. 15999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>Women Solid Leather Pumps</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0   Mi Notebook Horizon Edition 14 Intel Core i5-1...   \n",
       "1   Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...   \n",
       "2   HP Pavilion (2021) Thin & Light 11th Gen Core ...   \n",
       "3   Mi Notebook Horizon Edition 14 Intel Core i7-1...   \n",
       "4   ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...   \n",
       "..                                                ...   \n",
       "95  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...   \n",
       "96  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...   \n",
       "97  Dell Inspiron 15 Gaming 7567 15.6-inch Laptop ...   \n",
       "98  Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...   \n",
       "99  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...   \n",
       "\n",
       "                         description               Price  \n",
       "0        Women AIR MAX VIVA Sneakers   Rs. 9371Rs. 12495  \n",
       "1         Men Colourblocked Sneakers            Rs. 8650  \n",
       "2          Men Leather Chelsea Boots  Rs. 11305Rs. 11900  \n",
       "3        Men AIR ZOOM PEGASUS 38 Run            Rs. 9995  \n",
       "4   Men Perforations Leather Brogues            Rs. 6999  \n",
       "..                               ...                 ...  \n",
       "95     Men AIR MAX INFINITY Sneakers            Rs. 8295  \n",
       "96                    Women Sneakers           Rs. 12999  \n",
       "97       Women Solid Leather Loafers            Rs. 7999  \n",
       "98          Men Leather Formal Monks   Rs. 7999Rs. 15999  \n",
       "99         Women Solid Leather Pumps            Rs. 9999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products=pd.DataFrame({})\n",
    "products['Name']=product_titles[:100]\n",
    "products['description']=product_desc_M[:100]\n",
    "products['Price']=product_price_M[:100]\n",
    "\n",
    "products"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
